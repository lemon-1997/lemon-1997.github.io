<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>Google分布式框架Weaver（五）：实现自己的部署器</title><url>/post/frame-weaver-5.html</url><categories><category>框架教程</category></categories><tags><tag>go</tag><tag>weaver</tag><tag>微服务</tag></tags><content type="html"><![CDATA[上一节我们了解到了weavelet，envelope之间的通信，以及babysister是如何管理各个component，weaver命令多进程部署是如何工作的。 weaver支持开发者去实现部署，可以利用它去实现指定副本的多进程部署（weaver自带的命令默认副本数为2个），多机器部署等等，下面，我将介绍如何去实现自己的部署应用。
简单例子 前不久，weaver官方发布了关于部署的blog，https://serviceweaver.dev/blog/deployers.html，本文将基于官方的例子介绍。
要实现部署，我们必须去实现EnvelopeHandler接口
type EnvelopeHandler interface { // Components.  ActivateComponent(context.Context, *protos.ActivateComponentRequest) (*protos.ActivateComponentReply, error) // Listeners.  GetListenerAddress(context.Context, *protos.GetListenerAddressRequest) (*protos.GetListenerAddressReply, error) ExportListener(context.Context, *protos.ExportListenerRequest) (*protos.ExportListenerReply, error) // Telemetry.  HandleLogEntry(context.Context, *protos.LogEntry) error HandleTraceSpans(context.Context, []trace.ReadOnlySpan) error }  ActivateComponent：字面意思是激活组件，实际上我们应该去实现启动一个进程，启动服务接收来自其他组件对该组件的服务调用。 GetListenerAddress：获取组件监听地址，我们的应用需要暴露服务，所有需要指定它要开发的地址。 ExportListener：组件监听后，weavelet返回给envelope，可以使用代理，统一用一个地址对外暴露。 HandleLogEntry：组件的日志，也可以统一处理， HandleTraceSpans：组件的遥测数据。  当然了，在实现过程中，我们可能还需要借助envelope提供的函数去实现，像比如更新路由信息，更新组件等等。
// Components. func (e *Envelope) UpdateRoutingInfo(routing *protos.RoutingInfo) error func (e *Envelope) UpdateComponents(components []string) error // Telemetry. func (e *Envelope) GetHealth() protos.HealthStatus func (e *Envelope) GetMetrics() ([]*metrics.MetricSnapshot, error) func (e *Envelope) GetLoad() (*protos.LoadReport, error) func (e *Envelope) GetProfile(req *protos.GetProfileRequest) ([]byte, error) 首先，定义deployer
package main type deployer struct { mu sync.Mutex // guards handlers  handlers map[string]*handler // handlers, by component } type handler struct { deployer *deployer // underlying deployer  envelope *envelope.Envelope // envelope to the weavelet  address string // weavelet&#39;s address } var _ envelope.EnvelopeHandler = &amp;handler{} 第二步，实现spawn方法生成weavelet
func (d *deployer) spawn(component string) (*handler, error) { d.mu.Lock() defer d.mu.Unlock() // 防止重复生成weavelet（每次启动应用时，都会get其他组件，防止无限创建组件）  h, ok := d.handlers[component] if ok { return h, nil } // Spawn a weavelet in a subprocess to host the component.  info := &amp;protos.EnvelopeInfo{ App: &#34;app&#34;, // the application name  DeploymentId: deploymentId, // the deployment id  Id: uuid.New().String(), // the weavelet id  SingleProcess: false, // is the app a single process?  SingleMachine: true, // is the app on a single machine?  RunMain: component == &#34;main&#34;, // should the weavelet run main?  } config := &amp;protos.AppConfig{ Name: &#34;app&#34;, // the application name  Binary: flag.Arg(0), // 通过命令行参数传入  } // NewEnvelope会创建一个进程，运行指定的Binary，并通过管道进行通信，上一节有介绍  envelope, err := envelope.NewEnvelope(context.Background(), info, config) if err != nil { return nil, err } h = &amp;handler{ deployer: d, envelope: envelope, address: envelope.WeaveletInfo().DialAddr, } go func() { // Inform the weavelet of the component it should host.  envelope.UpdateComponents([]string{component}) // Handle messages from the weavelet.  envelope.Serve(h) }() // Return the handler.  d.handlers[component] = h return h, nil } 接下来，实现ActivateComponent，当weaver.Get使用被调用
func (h *handler) ActivateComponent(_ context.Context, req *protos.ActivateComponentRequest) (*protos.ActivateComponentReply, error) { // 通过spawn创建出组件  spawned, err := h.deployer.spawn(req.Component) if err != nil { return nil, err } // 更新路由信息  h.envelope.UpdateRoutingInfo(&amp;protos.RoutingInfo{ Component: req.Component, Replicas: []string{spawned.address}, }) return &amp;protos.ActivateComponentReply{}, nil } 如果我们的应用需要对外暴露，那么需要实现GetListenerAddress，ExportListener
// 随机监听本机的一个端口 func (h *handler) GetListenerAddress(_ context.Context, req *protos.GetListenerAddressRequest) (*protos.GetListenerAddressReply, error) { return &amp;protos.GetListenerAddressReply{Address: &#34;localhost:0&#34;}, nil } // 这里没做代理，只做打印 func (h *handler) ExportListener(_ context.Context, req *protos.ExportListenerRequest) (*protos.ExportListenerReply, error) { fmt.Printf(&#34;Weavelet listening on %s\n&#34;, req.Address) return &amp;protos.ExportListenerReply{}, nil } 然后是遥测，只是实现，不做处理
func (h *handler) HandleLogEntry(_ context.Context, entry *protos.LogEntry) error { pp := logging.NewPrettyPrinter(colors.Enabled()) fmt.Println(pp.Format(entry)) return nil } func (h *handler) HandleTraceSpans(context.Context, []trace.ReadOnlySpan) error { return nil } 最后是实现cmd命令
func main() { flag.Parse() d := &amp;deployer{handlers: map[string]*handler{}} d.spawn(&#34;main&#34;) select {} // block forever } 这样一来，就可以通过我们自己写的部署器去实现多进程部署了。 上面只是weaver官方给的简单例子，实际上，weaver自己的多进程部署还多了其他功能，具体可以看源码，源码还有多机器的SSH方式部署。
k8s 关于k8s部署weaver应用，官方只提供了weaver gke的方式，如果想要在自己的k8s环境上构建，得需要自己去实现k8s部署器。 按我的理解，如果要实现，可能要分成两个部分，一个用来实现EnvelopeHandler方法，属于上层，一个有k8s权限，可以在k8s创建容器，并接收另一个创建组件的请求，可以与k8s内的组件通信。 当然，实际情况可能考虑的问题还不少，这只是我的简单想法，等官方实现可能还要等一段时间，目前还没用看到weaver团队的计划。
结尾 如果对weaver有兴趣的话，欢迎在下方讨论。
]]></content></entry><entry><title>Google分布式框架Weaver（四）：多进程部署原理</title><url>/post/frame-weaver-4.html</url><categories><category>框架教程</category></categories><tags><tag>go</tag><tag>weaver</tag><tag>微服务</tag></tags><content type="html"><![CDATA[到上一小节，我们已经学会了如何去使用weaver进行项目开发，相信很多人对weaver的原理很感兴趣，想了解weaver内部到底是如何实现的。 这一节，我将介绍weaver在多进程部署中，组件之间的通信过程。
codegen 在看源码之前，我们可以先阅读weaver生成的代码。
func init() { codegen.Register(codegen.Registration{ Name: &#34;github.com\\lemon-1997\\weaver\\service\\product\\T&#34;, Iface: reflect.TypeOf((*T)(nil)).Elem(), New: func() any { return &amp;impl{} }, ConfigFn: func(i any) any { return i.(*impl).WithConfig.Config() }, LocalStubFn: func(impl any, tracer trace.Tracer) any { return t_local_stub{impl: impl.(T), tracer: tracer} }, ClientStubFn: func(stub codegen.Stub, caller string) any { return t_client_stub{stub: stub, listMetrics: codegen.MethodMetricsFor(codegen.MethodLabels{Caller: caller, Component: &#34;github.com\\lemon-1997\\weaver\\service\\product\\T&#34;, Method: &#34;List&#34;}), createMetrics: codegen.MethodMetricsFor(codegen.MethodLabels{Caller: caller, Component: &#34;github.com\\lemon-1997\\weaver\\service\\product\\T&#34;, Method: &#34;Create&#34;}), updateMetrics: codegen.MethodMetricsFor(codegen.MethodLabels{Caller: caller, Component: &#34;github.com\\lemon-1997\\weaver\\service\\product\\T&#34;, Method: &#34;Update&#34;}), deleteMetrics: codegen.MethodMetricsFor(codegen.MethodLabels{Caller: caller, Component: &#34;github.com\\lemon-1997\\weaver\\service\\product\\T&#34;, Method: &#34;Delete&#34;})} }, ServerStubFn: func(impl any, addLoad func(uint64, float64)) codegen.Server { return t_server_stub{impl: impl.(T), addLoad: addLoad} }, }) } 这里可以看到codegen会注册我们的组件，比较重要的是这三个函数LocalStubFn，ClientStubFn，ServerStubFn。
 LocalStubFn返回本地调用对象t_local_stub，t_local_stub实现了product/T的接口。 ClientStubFn返回RPC客户端t_client_stub，t_client_stub实现了product/T的接口。 ServerStubFn返回RPC服务端t_server_stub，t_server_stub处理来自t_client_stub的调用。  这里估计大多数应该可以猜到，LocalStubFn是用于单进程部署，而ClientStubFn，ServerStubFn则会在多进程部署用到。
weavelet weavelet在weaver中是用来管理组件，每个进程中都会有一个weavelet（通过weaver.Init创建）。
func Init(ctx context.Context) Instance { root, err := initInternal(ctx) if err != nil { fmt.Fprintln(os.Stderr, fmt.Errorf(&#34;error initializing Service Weaver: %w&#34;, err)) os.Exit(1) } return root } func initInternal(ctx context.Context) (Instance, error) { wlet, err := newWeavelet(ctx, codegen.Registered()) if err != nil { return nil, fmt.Errorf(&#34;internal error creating weavelet: %w&#34;, err) } return wlet.start() } weavelet初始化时会拿到组件注册的信息（codegen.Registered），注册服务（前面生成代码提到的PRC服务端）。
func (w *weavelet) start() (Instance, error) { ... handlers := &amp;call.HandlerMap{} for _, c := range w.componentsByName { w.addHandlers(handlers, c) } ... } envelope envelope运行在部署进程中，能够和weavelet进行通讯，双方是利用管道发送消息，有两条管道，一个是weavelet=&gt;envelope，另一个是envelope=&gt;weavelet。 envelope的主要作用是检查weavelet的运行状态，通知订阅weavelet组件的路由信息，处理来自weavelet的消息，如创建新的组件，http代理等等。
type EnvelopeHandler interface { // StartComponent starts the given component. 	StartComponent(entry *protos.ComponentToStart) error // GetAddress gets the address a weavelet should listen on for a listener. 	GetAddress(req *protos.GetAddressRequest) (*protos.GetAddressReply, error) // ExportListener exports the given listener. 	ExportListener(req *protos.ExportListenerRequest) (*protos.ExportListenerReply, error) // RecvLogEntry enables the envelope to receive a log entry. 	RecvLogEntry(entry *protos.LogEntry) // RecvTraceSpans enables the envelope to receive a sequence of trace spans. 	RecvTraceSpans(spans []trace.ReadOnlySpan) error } babysitter babysitter运行在部署进程上，管理了所有envelope，是weaver中的大脑。 当我们运行命令weave mulit deploy时，会创建babysitter，babysitter会固定创建出两个main组件。 这两个main组件运行在不同进程，执行配置文件指定的binary文件。一般来说，我们会指定http服务的端口号。
func (s *Server) Run(addr string) error { lis, err := s.root.Listener(&#34;lemon&#34;, weaver.ListenerOptions{LocalAddress: addr}) if err != nil { return err } s.root.Logger().Debug(&#34;listener available&#34;, &#34;addr&#34;, lis) return http.Serve(lis, otelhttp.NewHandler(http.DefaultServeMux, &#34;http&#34;)) } weaver为了防止端口被占用，实际上两个main进程绑定的都是随机的端口，通过weavelet调用ExportListener发送到envelope，由babysitter处理代理的逻辑
func (b *Babysitter) ExportListener(req *protos.ExportListenerRequest) (*protos.ExportListenerReply, error) { if p, ok := b.proxies[req.Listener.Name]; ok { p.proxy.AddBackend(req.Listener.Addr) return &amp;protos.ExportListenerReply{ProxyAddress: p.addr}, nil } lis, err := net.Listen(&#34;tcp&#34;, req.LocalAddress) if errors.Is(err, syscall.EADDRINUSE) { // Don&#39;t retry if this address is already in use. 	return &amp;protos.ExportListenerReply{Error: err.Error()}, nil } if err != nil { return nil, fmt.Errorf(&#34;proxy listen: %w&#34;, err) } addr := lis.Addr().String() b.logger.Info(&#34;Proxy listening&#34;, &#34;address&#34;, addr) proxy := proxy.NewProxy(b.logger) proxy.AddBackend(req.Listener.Addr) b.proxies[req.Listener.Name] = &amp;proxyInfo{ listener: req.Listener.Name, proxy: proxy, addr: addr, } go func() { if err := serveHTTP(b.ctx, lis, proxy); err != nil { b.logger.Error(&#34;proxy&#34;, err) } }() return &amp;protos.ExportListenerReply{ProxyAddress: addr}, nil } 在main程序执行过程中，程序会调用到weaver.Get来获取组件。
func Get[T any](requester Instance) (T, error) { var zero T iface := reflect.TypeOf(&amp;zero).Elem() rep := requester.rep() component, err := rep.wlet.getComponentByType(iface) if err != nil { return zero, err } result, err := rep.wlet.getInstance(component, rep.info.Name) if err != nil { return zero, err } return result.(T), nil } 在第一次获取组件的过程中需要初始化，main进程调用RegisterComponentToStart中向babysitter发送需要初始化的组件， babysitter收到请求后，会创建两个新的子进程，子进程创建后weavelet会把自己组件的tcp地址发送回babysitter， babysitter会把路由信息发送给订阅的weavelet组件。
func (h *handler) StartComponent(req *protos.ComponentToStart) error { if err := h.subscribeTo(req); err != nil { return err } return h.startComponent(req) } 这样一来，当进程调用组件的方法时，就能拿到组件提供RPC服务的地址，完成组件方法的调用，最终的程序多进程部署后会像这样。
$ weaver multi status ╭────────────────────────────────────────────────────╮ │ DEPLOYMENTS │ ├───────┬──────────────────────────────────────┬─────┤ │ APP │ DEPLOYMENT │ AGE │ ├───────┼──────────────────────────────────────┼─────┤ │ lemon │ f74f7512-a8ff-48e2-bdce-8a1a3dd4c640 │ 22s │ ╰───────┴──────────────────────────────────────┴─────╯ ╭──────────────────────────────────────────────────────────────────────────╮ │ COMPONENTS │ ├───────┬────────────┬──────────────────────────────────────┬──────────────┤ │ APP │ DEPLOYMENT │ COMPONENT │ REPLICA PIDS │ ├───────┼────────────┼──────────────────────────────────────┼──────────────┤ │ lemon │ f74f7512 │ lemon\service\category\T │ 10272, 15264 │ │ lemon │ f74f7512 │ lemon\service\category\categoryCache │ 4692, 15116 │ │ lemon │ f74f7512 │ lemon\service\product\T │ 11788, 13260 │ │ lemon │ f74f7512 │ main │ 4508, 13236 │ ╰───────┴────────────┴──────────────────────────────────────┴──────────────╯ ╭─────────────────────────────────────────────────╮ │ LISTENERS │ ├───────┬────────────┬──────────┬─────────────────┤ │ APP │ DEPLOYMENT │ LISTENER │ ADDRESS │ ├───────┼────────────┼──────────┼─────────────────┤ │ lemon │ f74f7512 │ lemon │ 127.0.0.1:12345 │ ╰───────┴────────────┴──────────┴─────────────────╯ 每个组件都运行在两个不同的进程，main处理http服务，其他组件各自处理自己的服务，这8个进程都是部署进程的子进程，通过管道进行通信，同步组件服务的路由， main最早被初始化，后续通过weaver.Get不断创建新的组件进程。
小结 讲的比较简单，只是个大概，有兴趣的可以去看github上的源码，比较有意思，我在看源码的过程中也修了两个Windows上的兼容bug，算是有所收获。
]]></content></entry><entry><title>Google分布式框架Weaver（三）：测试与可观测性</title><url>/post/frame-weaver-3.html</url><categories><category>框架教程</category></categories><tags><tag>go</tag><tag>weaver</tag><tag>微服务</tag></tags><content type="html"><![CDATA[上一次我们通过weaver中的组件完成了一个简易的商品后台系统，并对外提供http接口。 但是在实际开发中，除了业务逻辑的实现，少不了测试代码，也少不了可观测性（日志，指标，链路追踪）。
测试 weaver官方提供了weavertest给开发者去测试自己的服务，weavertest对外只提供一个接口weavertest.Init
func Init(ctx context.Context, t testing.TB, opts Options) weaver.Instance 调用该接口我们可以拿到weaver.Instance，以此获取我们需要测试的组件。 该接口参数比较简单，主要是Options
type Options struct { // 是否单进程 	SingleProcess bool // 配置文件的字符串内容 	Config string } 好，现在要测试上次的缓存路由能否生效，并测试增删改查的逻辑是否正确，我们使用表格驱动测试的方式编写
func TestCache(t *testing.T) { ctx := context.Background() root := weavertest.Init(ctx, t, weavertest.Options{SingleProcess: false}) cache, err := weaver.Get[categoryCache](root) if err != nil { t.Fatal(err) } tests := []struct { name string id int64 want Category wantErr bool fun func(c categoryCache) error }{ { name: &#34;Add&#34;, id: 1, want: Category{ID: 1, Name: &#34;1&#34;}, wantErr: false, fun: func(c categoryCache) error { return cache.Add(ctx, 1, Category{ID: 1, Name: &#34;1&#34;}) }, }, { name: &#34;Update&#34;, id: 2, want: Category{ID: 2, Name: &#34;2&#34;}, wantErr: false, fun: func(c categoryCache) error { if err = cache.Add(ctx, 2, Category{ID: 2, Name: &#34;1&#34;}); err != nil { return err } if err = cache.Add(ctx, 2, Category{ID: 2, Name: &#34;2&#34;}); err != nil { return err } return nil }, }, { name: &#34;Remove&#34;, id: 1, wantErr: true, fun: func(c categoryCache) error { return cache.Remove(ctx, 1) }, }, } for _, tt := range tests { t.Run(tt.name, func(t *testing.T) { if err = tt.fun(cache); err != nil { t.Fatal(err) } got, err := cache.Get(context.Background(), tt.id) if (err != nil) != tt.wantErr { t.Errorf(&#34;Get() error = %v, wantErr %v&#34;, err, tt.wantErr) return } if !reflect.DeepEqual(got, tt.want) { t.Errorf(&#34;Get() got = %v, want %v&#34;, got, tt.want) } }) } } 在测试商品的逻辑时，我们需要配置文件的数据库信息，可以这样初始化
func TestProduct(t *testing.T) { ctx := context.Background() root := weavertest.Init(ctx, t, weavertest.Options{ SingleProcess: true, Config: ` [&#34;lemon\\service\\product\\T&#34;] dsn = &#34;test.db&#34;`, }) service, err := weaver.Get[T](root) if err != nil { t.Fatal(err) } } 日志 日志也是我们写代码的关键一环，排查问题通常都是靠它。weaver也提供了自己的logger，每个组件都持有自己的logger
type Logger interface { Debug(msg string, attributes ...any) Info(msg string, attributes ...any) Error(msg string, err error, attributes ...any) With(attributes ...any) Logger } 日志的接口比较简单，下面给一些演示
func (s *impl) LogWithTrace(ctx context.Context) weaver.Logger { span := trace.SpanFromContext(ctx) return s.Logger().With( &#34;spanID&#34;, span.SpanContext().SpanID().String(), &#34;traceID&#34;, span.SpanContext().TraceID().String()) } func (s *impl) Get(ctx context.Context, id int64) (Category, error) { cate, err := s.cache.Get(ctx, id) if err != nil { s.LogWithTrace(ctx).Error(&#34;cache Get err&#34;, err, &#34;id&#34;, id) } return cate, nil } func (s *impl) Create(ctx context.Context, category Category) error { if err := s.cache.Add(ctx, category.ID, category); err != nil { s.LogWithTrace(ctx).Error(&#34;cache Add err&#34;, err, &#34;id&#34;, category.ID) } return nil } func (s *impl) Update(ctx context.Context, id int64, category Category) error { if err := s.cache.Add(ctx, id, category); err != nil { s.LogWithTrace(ctx).Error(&#34;cache Add err&#34;, err, &#34;id&#34;, id) } return nil } 这是缓存日志的代码，这里我封装了LogWithTrace把spanID以及traceID注入到日志中，方便和链路追踪系统配合排查原因， 打印后的日志大概长这样
E0321 20:03:02.403842 lemon\service\category\T 27e41665 service.go:45] cache Get err err=&#34;record not found&#34; id=&#34;1&#34; spanID=&#34;1a3177735a5c65b3&#34; traceID=&#34;3617bf1460d2ae17a3f54eabc14296ba&#34; 指标 采集指标，并将指标可视化，可以评估我们服务的可靠性和稳定性，通过指标的变化即使预警，可以让我们及时感知并做出处理。 weaver提供了三种指标，分别是
 counter：计数器 gauges：仪表盘 histograms：直方图  下面以计数器为例，计算一个函数被调用的次数
import &#34;github.com/ServiceWeaver/weaver/metrics&#34; var ( count = metrics.NewCounter( &#34;count&#34;, &#34;count number&#34;, ) ) func testFun(_ context.Context) (error) { addCount.Add(1) // 其他逻辑 .... return nil } 不仅如此，在上次我们写的对外API中，使用了weaver.InstrumentHandlerFunc
func (s *Server) registerHandler() { instrument := func(label string, fn func(http.ResponseWriter, *http.Request)) http.Handler { return weaver.InstrumentHandlerFunc(label, func(w http.ResponseWriter, r *http.Request) { span := trace.SpanFromContext(r.Context()) span.SetAttributes(attribute.String(&#34;http.path&#34;, r.URL.Path)) fn(w, r) }) } http.Handle(&#34;/product&#34;, instrument(&#34;product&#34;, s.productHandler)) http.Handle(&#34;/category&#34;, instrument(&#34;category&#34;, s.categoryHandler)) } 而在该函数中，它帮我们实现了几个http通用指标，无需重复编写
func InstrumentHandler(label string, handler http.Handler) http.Handler { return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) { start := time.Now() labels := httpLabels{Label: label, Host: r.Host} // http调用次数 	httpRequestCounts.Get(labels).Add(1) defer func() { // http请求时间 	httpRequestLatencyMicros.Get(labels).Put( float64(time.Since(start).Microseconds())) }() if size, ok := requestSize(r); ok { // http接受字节大小 	httpRequestBytesReceived.Get(labels).Put(float64(size)) } writer := responseWriterInstrumenter{w: w} handler.ServeHTTP(&amp;writer, r) if writer.statusCode &gt;= 400 &amp;&amp; writer.statusCode &lt; 600 { // http处理失败次数 	httpRequestErrors.Get(httpErrorLabels{ Label: label, Host: r.Host, Code: writer.statusCode, }).Add(1) } // http返回字节大小 	httpRequestBytesReturned.Get(labels).Put(float64(writer.responseSize(r))) }) } 而针对每个组件，weaver也会自动生成指标，有兴趣可以自己看看源码。
链路追踪 微服务架构导致一个接口，可能会经过到五六个系统，甚至更多，这会导致出现问题很难排查，而有了链路追踪，每一个请求都将清晰明了，可以快速地定位是哪个服务出现问题。 在weaver的生成代码中，它为每个组件的方法都加上了链路追踪，不过前提是我们需要初始化
func (s *Server) Run(addr string) error { lis, err := s.root.Listener(&#34;lemon&#34;, weaver.ListenerOptions{LocalAddress: addr}) if err != nil { return err } s.root.Logger().Debug(&#34;listener available&#34;, &#34;addr&#34;, lis) // 初始化 	return http.Serve(lis, otelhttp.NewHandler(http.DefaultServeMux, &#34;http&#34;)) } 生成的调用代码
func (s t_local_stub) List(ctx context.Context, a0 []int64) (r0 []Product, err error) { span := trace.SpanFromContext(ctx) if span.SpanContext().IsValid() { // Create a child span for this method. 	ctx, span = s.tracer.Start(ctx, &#34;product.T.List&#34;, trace.WithSpanKind(trace.SpanKindInternal)) defer func() { if err != nil { span.RecordError(err) span.SetStatus(codes.Error, err.Error()) } span.End() }() } return s.impl.List(ctx, a0) } 小结 这一节了解了weaver中的测试以及可观测的API，并把它加入到我们的商品后台项目。 收集到的指标，链路追踪都可以通过weaver dashboard去查看，这个大家自行了解。
项目源码：https://github.com/lemon-1997/weaver-example
]]></content></entry><entry><title>Google分布式框架Weaver（二）：组件搭建商品后台</title><url>/post/frame-weaver-2.html</url><categories><category>框架教程</category></categories><tags><tag>go</tag><tag>weaver</tag><tag>微服务</tag></tags><content type="html"><![CDATA[组件是weaver中的一个核心抽象，在我们的应用中，组件是一组接口的实现，可以理解为微服务对外提供的API。 所以，组件是学习这个框架的第一步，接下来我将使用组件从零搭建一个简易的商品后台系统。
设计 假设我们正在构建一个在线商店的后端服务，需要设计一个商品管理系统。该系统需要实现对商品的创建、读取、更新和删除操作，以及支持商品的分类管理。 针对该场景我们可以设计两张表：
商品表（product）
   字段 备注     id 商品ID（主键，自增）   name 商品名称   description 商品描述   price 商品价格   category_id 商品分类ID   created_at 创建时间   updated_at 更新时间    商品分类表（category）
   字段 备注     id 分类ID（主键，自增）   name 分类名称    实现 确定了表设计之后，接下来就是代码实现了。
商品 首先是确定商品实体结构，并抽象出对外调用的接口。
type Product struct { weaver.AutoMarshal ID int64 `gorm:&#34;column:id&#34;` Name string `gorm:&#34;column:name&#34;` Description string `gorm:&#34;column:description&#34;` Price float64 `gorm:&#34;column:price&#34;` CategoryId int64 `gorm:&#34;column:category_id&#34;` CreatedAt time.Time `gorm:&#34;column:created_at&#34;` UpdatedAt time.Time `gorm:&#34;column:updated_at&#34;` } type T interface { List(ctx context.Context, ids []int64) ([]Product, error) Create(ctx context.Context, product Product) (int64, error) Update(ctx context.Context, id int64, product Product) error Delete(ctx context.Context, id int64) error } 这里Product结构嵌入了weaver.AutoMarshal，它能够让我们在使用weaver generate时生成WeaverMarshal和WeaverUnmarshal，因为组件之间的调用可能是使用rpc，因此需要序列化。 不过这里要注意，weaver.AutoMarshal并不是所以类型都能序列化，比如channel，func()都是无法生成代码的。 接下来，我们需要实现以上接口，先定义impl结构。
type impl struct { weaver.Implements[T] weaver.WithConfig[config] db *gorm.DB } type config struct { Dsn string `toml:&#34;dsn&#34;` } impl中嵌入了weaver.Implements和weaver.WithConfig，其中weaver.Implements[T]表示你实现了接口T, 后续weaver generate生成代码的调用就是使用你的实现，所以要想对外提供服务，这个是必须嵌入的字段。 weaver.WithConfig则表明你的组件需要配置，在初始化组件时就会去解析配置文件并转化好我们需要的结构， 在这里我们只需要dsn，所以我们在配置文件加上两行。
[组件名] dsn = &#34;local.db&#34; 由于我们使用了数据库，所以我们需要实现init函数，组件初始化时weaver会判断我们是否实现了init(ctx) err，有则会调用，所以并不是所以的组件都必须实现。
func (s *impl) Init(_ context.Context) error { cfg := s.Config() db, err := gorm.Open(sqlite.Open(cfg.Dsn), &amp;gorm.Config{}) if err != nil { return errors.New(&#34;failed to connect database&#34;) } // Migrate the schema 	if err = db.AutoMigrate(&amp;Product{}); err != nil { return err } s.db = db return nil } 最后实现商品的curd接口。
func (s *impl) List(ctx context.Context, ids []int64) (list []Product, err error) { if err = s.db.WithContext(ctx).Find(&amp;list, ids).Error; err != nil { s.Logger().Error(&#34;db Find error&#34;, err, &#34;ids&#34;, ids) } return } func (s *impl) Create(ctx context.Context, product Product) (id int64, err error) { if err = s.db.WithContext(ctx).Create(&amp;product).Error; err != nil { s.Logger().Error(&#34;db Create error&#34;, err, &#34;product&#34;, product) } return product.ID, err } func (s *impl) Update(ctx context.Context, id int64, product Product) error { if err := s.db.WithContext(ctx).Model(&amp;Product{}).Where(`id = ?`, id).Updates(&amp;product).Error; err != nil { s.Logger().Error(&#34;db Updates error&#34;, err, &#34;id&#34;, id) } return nil } func (s *impl) Delete(ctx context.Context, id int64) error { if err := s.db.WithContext(ctx).Delete(&amp;Product{}, id).Error; err != nil { s.Logger().Error(&#34;db Delete error&#34;, err, &#34;id&#34;, id) } return nil } 分类 分类这里，由于weaver提供了会话路由功能，所以可以使用内存的方式去存储商品分类，我们抽象出一个分类缓存。
type categoryCache interface { Add(context.Context, int64, Category) error Get(context.Context, int64) (Category, error) Remove(context.Context, int64) error } type categoryCacheImpl struct { weaver.Implements[categoryCache] weaver.WithRouter[categoryCacheRouter] cache sync.Map } 缓存的实现内嵌了weaver.Implements和weaver.WithRouter，weaver.Implements我们已经知道用法了，那么weaver.WithRouter呢？ weaver.WithRouter[categoryCacheRouter]表示当你调用组件的方法时，它会调用categoryCacheRouter的同名方法返回的key去路由，所以我们需要实现categoryCacheRouter。
type categoryCacheRouter struct{} func (categoryCacheRouter) Add(_ context.Context, key int64, _ Category) int64 { return key } func (categoryCacheRouter) Get(_ context.Context, key int64) int64 { return key } func (categoryCacheRouter) Remove(_ context.Context, key int64) int64 { return key } 不过要注意，必须是跟组件的接口同名，且返回的key有要求，必须是integer，float或string。 这样一来，调用缓存时，相同的key都会路由到同一进程，因此我们可以放到内存去做。
func (c *categoryCacheImpl) Add(_ context.Context, id int64, category Category) error { c.cache.Store(id, category) return nil } func (c *categoryCacheImpl) Get(_ context.Context, id int64) (Category, error) { value, ok := c.cache.Load(id) if !ok { return Category{}, errors.New(&#34;record not found&#34;) } cate, ok := value.(Category) if !ok { return Category{}, errors.New(&#34;data error&#34;) } return cate, nil } func (c *categoryCacheImpl) Remove(_ context.Context, id int64) error { c.cache.Delete(id) return nil } 缓存实现了，接下来封装商品分类的服务。
type Category struct { weaver.AutoMarshal ID int64 Name string } type T interface { Get(ctx context.Context, id int64) (Category, error) Create(ctx context.Context, category Category) error Update(ctx context.Context, id int64, category Category) error } type impl struct { weaver.Implements[T] cache categoryCache } func (s *impl) Init(context.Context) error { cache, err := weaver.Get[categoryCache](s) if err != nil { return err } s.cache = cache return nil } func (s *impl) LogWithTrace(ctx context.Context) weaver.Logger { span := trace.SpanFromContext(ctx) return s.Logger().With( &#34;spanID&#34;, span.SpanContext().SpanID().String(), &#34;traceID&#34;, span.SpanContext().TraceID().String()) } func (s *impl) Get(ctx context.Context, id int64) (Category, error) { cate, err := s.cache.Get(ctx, id) if err != nil { s.LogWithTrace(ctx).Error(&#34;cache Get err&#34;, err, &#34;id&#34;, id) } return cate, nil } func (s *impl) Create(ctx context.Context, category Category) error { if err := s.cache.Add(ctx, category.ID, category); err != nil { s.LogWithTrace(ctx).Error(&#34;cache Add err&#34;, err, &#34;id&#34;, category.ID) } return nil } func (s *impl) Update(ctx context.Context, id int64, category Category) error { if err := s.cache.Add(ctx, id, category); err != nil { s.LogWithTrace(ctx).Error(&#34;cache Add err&#34;, err, &#34;id&#34;, id) } return nil } 最后记得weaver generate生成组件的调用代码
API 最后就是提供API接口了，weaver提供了Listener方法去创建服务
type Server struct { root weaver.Instance product product.T category category.T } func NewServer(root weaver.Instance) (*Server, error) { productSvc, err := weaver.Get[product.T](root) if err != nil { return nil, err } categorySvc, err := weaver.Get[category.T](root) if err != nil { return nil, err } s := &amp;Server{ root: root, product: productSvc, category: categorySvc, } s.registerHandler() return s, nil } func (s *Server) Run(addr string) error { lis, err := s.root.Listener(&#34;lemon&#34;, weaver.ListenerOptions{LocalAddress: addr}) if err != nil { return err } s.root.Logger().Debug(&#34;listener available&#34;, &#34;addr&#34;, lis) return http.Serve(lis, otelhttp.NewHandler(http.DefaultServeMux, &#34;http&#34;)) } 实现路由逻辑
func (s *Server) registerHandler() { instrument := func(label string, fn func(http.ResponseWriter, *http.Request)) http.Handler { return weaver.InstrumentHandlerFunc(label, func(w http.ResponseWriter, r *http.Request) { span := trace.SpanFromContext(r.Context()) span.SetAttributes(attribute.String(&#34;http.path&#34;, r.URL.Path)) fn(w, r) }) } http.Handle(&#34;/product&#34;, instrument(&#34;product&#34;, s.productHandler)) http.Handle(&#34;/category&#34;, instrument(&#34;category&#34;, s.categoryHandler)) } func (s *Server) productHandler(w http.ResponseWriter, r *http.Request) { switch r.Method { case http.MethodGet: s.getProduct(w, r) case http.MethodPost: s.createProduct(w, r) case http.MethodPut: s.updateProduct(w, r) case http.MethodDelete: s.deleteProduct(w, r) default: http.Error(w, &#34;method not allowed&#34;, http.StatusMethodNotAllowed) } } func (s *Server) categoryHandler(w http.ResponseWriter, r *http.Request) { switch r.Method { case http.MethodGet: s.getCategory(w, r) case http.MethodPost: s.createCategory(w, r) case http.MethodPut: s.updateCategory(w, r) default: http.Error(w, &#34;method not allowed&#34;, http.StatusMethodNotAllowed) } } handler代码较长，这里就不展示了，需要可以到github仓库看。
小结 在这篇博客，我们了解了weaver.Implements，WithRouter，WithConfig以及AutoMarshal的使用，并实现了一个简单的商品后台管理系统。
项目源码：https://github.com/lemon-1997/weaver-example
]]></content></entry><entry><title>Google分布式框架Weaver（一）：单体开发，微服务运行</title><url>/post/frame-weaver.html</url><categories><category>框架教程</category></categories><tags><tag>go</tag><tag>weaver</tag><tag>微服务</tag></tags><content type="html"><![CDATA[最近，Google开源了一个用于编写、部署和管理分布式应用程序的编程框架：Service Weaver。 这个框架设计思想很巧妙，使用该框架可以以函数调用的方式去调用其他服务，无需考虑任何网络或者序列化问题，在部署时却能够以微服务的方式运行。 这样一来，开发者可以在自己的机器上运行、测试和调试，非常的方便。
weaver简介 讲weaver之前，必须先讲下微服务，微服务是一种架构风格，通过将应用程序划分为一组小的、相互独立的服务来构建大型应用程序。尽管微服务架构带来了许多好处，但也存在缺点。
微服务痛点  复杂性：微服务架构通常需要将一个应用程序分成多个服务，这样就需要管理和维护多个服务。这增加了应用程序的复杂性，需要额外的工作来确保所有服务能够相互协作。 分布式系统：微服务架构通常是基于分布式系统的，而分布式系统通常比单体应用程序更难以管理和维护。这是因为它涉及到不同的服务运行在不同的机器上，需要处理网络故障、数据同步和一致性等问题。 版本控制：微服务架构中的每个服务都需要进行版本控制，这会增加代码库的复杂性和维护成本。同时，服务之间的接口和依赖关系也需要进行版本控制和管理，以确保不会发生兼容性问题。 监控和调试：微服务架构中的服务可能会分布在不同的机器和数据中心，因此对系统进行监控和调试变得更加困难。同时，由于服务之间存在依赖关系，当一个服务出现问题时，可能会影响整个系统的运行。 测试：微服务架构中的每个服务都需要进行单元测试、集成测试和端到端测试等多种测试，这会增加测试的复杂性和维护成本。同时，由于服务之间存在依赖关系，测试也需要考虑服务之间的交互和一致性。  特性 使用weaver我们不用担心以上的问题，我们只需要编写业务代码，微服务的问题交给weaver处理。
 Components：组件是weaver中的核心概念，它是一组方法的集合，即微服务对外提供的接口，在go中被抽象成了interface{}，可以直接函数调用。 Observability：weaver为可观测三大指标，日志，指标，链路追踪都封装了API给开发者使用。 Testing：weaver提供一个weavertest包，可以使用它来测试的weaver服务。 Versioning：weaver保证在滚动更新时所以的服务都处在同一版本，不会出现不同版本的服务相互调用的情况。 Deploy：weaver配置，部署命令简单，开发者无需编写多个微服务的部署文件。  部署 weaver支持三种部署模式：
 single process：单进程部署，服务之间的调用都是函数调用。 multi process：多进程部署，服务会创建多个副本，每个副本都是单独的进程。 GKE（Google Kubernetes Engine (GKE)）：多机器部署到云端。  weaver安装 安装 weaver使用也很简单，首先根据官方文档先编写一个简单的反转字符串接口，这里直接复制，后续会讲到weaver提供的接口以及实现原理
package main import ( &#34;context&#34; &#34;fmt&#34; &#34;log&#34; &#34;net/http&#34; &#34;github.com/ServiceWeaver/weaver&#34; ) // Reverser component. type Reverser interface { Reverse(context.Context, string) (string, error) } // Implementation of the Reverser component. type reverser struct { weaver.Implements[Reverser] } func (r *reverser) Reverse(_ context.Context, s string) (string, error) { runes := []rune(s) n := len(runes) for i := 0; i &lt; n/2; i++ { runes[i], runes[n-i-1] = runes[n-i-1], runes[i] } return string(runes), nil } func main() { // Get a network listener on address &#34;localhost:12345&#34;. 	root := weaver.Init(context.Background()) opts := weaver.ListenerOptions{LocalAddress: &#34;localhost:12345&#34;} lis, err := root.Listener(&#34;hello&#34;, opts) if err != nil { log.Fatal(err) } fmt.Printf(&#34;hello listener available on %v\n&#34;, lis) // Get a client to the Reverser component. 	reverser, err := weaver.Get[Reverser](root) if err != nil { log.Fatal(err) } // Serve the /hello endpoint. 	http.HandleFunc(&#34;/hello&#34;, func(w http.ResponseWriter, r *http.Request) { reversed, err := reverser.Reverse(r.Context(), r.URL.Query().Get(&#34;name&#34;)) if err != nil { http.Error(w, err.Error(), http.StatusInternalServerError) } fmt.Fprintf(w, &#34;Hello, %s!\n&#34;, reversed) }) http.Serve(lis, nil) }  编写main文件，如上面的代码。 执行go mod tidy安装依赖。 执行go install github.com/ServiceWeaver/weaver/cmd/weaver@latest安装weaver。 执行weaver generate .生成代码。 执行go run . 测试curl &quot;localhost:12345/hello?name=Weaver&quot;返回反转的字符串Hello, revaeW!  遇到的问题 在安装的过程中难免会遇到问题，我把我遇到的问题也记录下，方便相同问题的人能解决
 gcc：具体的错误信息忘记保存了，大致是因为sqllite的依赖，遇到这个问题直接去装gcc并添加到环境变量就好了，大家都是程序员，我相信都能解决。 weaver multi deploy失败：这个问题是系统问题，因为linux子进程继承时可以把文件描述符也带过去，但是windows不支持，而weaver没有对这种情况做处理，导致无法在windows机器上部署多进程，这个我已经提给了官方，相信很快能处理。 weaver status报错：  Get &#34;http://127.0.0.1:12012/debug/serviceweaver/status&#34;: dial tcp 127.0.0.1:12012: connectex: No connection could be made because the target machine actively refused it 调试weaver代码后，我发现有些weaver服务即使退出了，weaver还认为它存在，所以请求该服务的状态时会失败。 最终发现是golang IDE在2022.3版本之前在debug调试下点击stop会发送os.kill信号（run模式下和ctrl+c都正常），而这个信号无法被捕获，导致weaver没能判断服务已经退出。 解决方案是删除~.local\share\serviceweaver\single_registry以及~.local\share\serviceweaver\multi_registry下面的文件即可正常运行。 为了防止再出现这种情况可以将golang IDE升级到2022.3版本修复这个问题。
小结 这篇blog先分享weaver的安装以及简介，后续会更详细地介绍这个框架。由于目前weaver还是在0.1版本，官方也明确表示不排除会有大改动。
]]></content></entry><entry><title>解决重复请求和缓存击穿，go神器SingleFlight深度解析</title><url>/post/source-singleFlight.html</url><categories><category>源码分析</category></categories><tags><tag>go</tag><tag>SingleFlight</tag><tag>缓存击穿</tag></tags><content type="html"><![CDATA[当应用程序面临高并发请求时，重复请求往往是一种常见的问题。针对这一问题，Go 语言中提供了 SingleFlight 库，它可以有效地解决并发请求中的重复请求问题，提升应用程序的性能和稳定性。在本文中，我们将介绍 SingleFlight 库的作用和价值，并详细讲解如何在 Go 语言中使用 SingleFlight 库来解决并发请求中的重复请求问题。同时，我们将探讨 SingleFlight 库的原理和实现，以及其在实际项目中的应用场景和注意事项。
使用方式 我们可以直接在应用程序中导入 SingleFlight 库，并使用 Group 结构体和 Do 函数来解决并发请求中的重复请求问题。具体实现如下：
import ( &#34;golang.org/x/sync/singleflight&#34; ) var group singleflight.Group func exampleFunction() (interface{}, error) { result, err, _ := group.Do(&#34;key&#34;, func() (interface{}, error) { // 在这里写具体的业务逻辑  return &#34;value&#34;, nil }) if err != nil { return nil, err } return result, nil } 可以看到使用非常简单，当相同的key并发请求过来时，最终只有一个去调用函数，其他goruntine都会阻塞等待。 除了最基本的Do，go还提供了另外两个API：
func (g *Group) DoChan(key string, fn func() (interface{}, error)) &lt;-chan Result func (g *Group) Forget(key string) DoChan功能和Do是一样的，只是利用chan改为异步，而Forget则是可以清除某个key，不需要等到阻塞执行完才清除。
原理实现 结构 Group结构简单，mu是互斥锁，所以m的操作都会被锁住，m是一个map结构，每个key对应一个call结构。
type Group struct { mu sync.Mutex m map[string]*call } 接着是call结构
type call struct { // wg用于同步阻塞相同key的调用  wg sync.WaitGroup // val跟err存调用执行结果  val interface{} err error // forgotten是一个标志位，调用完成时调用forget函数，后面会具体讲作用  forgotten bool // dups记录重复调用的次数  dups int // chans发送调用结果给channel  chans []chan&lt;- Result } 这里的chan&lt;- Result 表示每个元素都是只能发送的chan，不能接受
type Result struct { Val interface{} Err error Shared bool } 这个是chan的返回结果，跟上面的一样就不重复讲了。
API Do方法通过mu，保证在并发的时候只有一个goruntine写入key，并执行调用fn，重复的key最终都会走wg.wait逻辑等待docall完成。
func (g *Group) Do(key string, fn func() (interface{}, error)) (v interface{}, err error, shared bool) { g.mu.Lock() // 懒加载  if g.m == nil { g.m = make(map[string]*call) } // 重复的key  if c, ok := g.m[key]; ok { c.dups++ g.mu.Unlock() // 阻塞等待  c.wg.Wait() if e, ok := c.err.(*panicError); ok { panic(e) } else if c.err == errGoexit { runtime.Goexit() } return c.val, c.err, true } c := new(call) c.wg.Add(1) g.m[key] = c g.mu.Unlock() // 调用fn  g.doCall(c, key, fn) return c.val, c.err, c.dups &gt; 0 } DoChan功能一样，只是返回chan，不阻塞直接返回
func (g *Group) DoChan(key string, fn func() (interface{}, error)) &lt;-chan Result { ch := make(chan Result, 1) g.mu.Lock() if g.m == nil { g.m = make(map[string]*call) } if c, ok := g.m[key]; ok { c.dups++ c.chans = append(c.chans, ch) g.mu.Unlock() return ch } c := &amp;call{chans: []chan&lt;- Result{ch}} c.wg.Add(1) g.m[key] = c g.mu.Unlock() go g.doCall(c, key, fn) return ch } 然后是docall逻辑，本该是个简单的函数，但是因为要区分panic和goexit，增加了复杂度
func (g *Group) doCall(c *call, key string, fn func() (interface{}, error)) { // 正常返回标志位  normalReturn := false // panic标志位  recovered := false defer func() { // 如果没有正常返回且不是panic  if !normalReturn &amp;&amp; !recovered { c.err = errGoexit } // fn执行完，c.val，c.err已经确定  c.wg.Done() g.mu.Lock() defer g.mu.Unlock() // 外部没有调用forget，需要自己删除key，防止后面相同key一直复用这个结果  if !c.forgotten { delete(g.m, key) } if e, ok := c.err.(*panicError); ok { // 防止channel阻塞，直接go panic()  if len(c.chans) &gt; 0 { go panic(e) select {} } else { // 正常返回，直接往上panic  panic(e) } } else if c.err == errGoexit { // goexit无需处理  } else { // 发送ch  for _, ch := range c.chans { ch &lt;- Result{c.val, c.err, c.dups &gt; 0} } } }() func() { defer func() { if !normalReturn { // 这里还无法确定panic还是goexit  if r := recover(); r != nil { c.err = newPanicError(r) } } }() c.val, c.err = fn() normalReturn = true }() // goexit无法到这里，如果这里没正常返回，则说明是panic，被recover了  if !normalReturn { recovered = true } } 由于panic和goexit都会进入recover，所以这里用了两次recover来区分这两种情况，主逻辑就是调用fn，获取结果，通知其他协程，删除掉key。
func (g *Group) Forget(key string) { g.mu.Lock() if c, ok := g.m[key]; ok { c.forgotten = true } delete(g.m, key) g.mu.Unlock() } Forget最简单，就是删key，然后更改forgotten标志位，防止docall去删除
小结 应用场景  缓存穿透：缓存穿透是指恶意请求或者缓存过期等原因导致大量请求直接落到数据库上，导致数据库压力过大。使用 SingleFlight 库可以在缓存未命中时，只有一个请求会去查询数据库，其他请求会等待第一个请求的结果并复用。 防止瞬间高并发：在高并发场景下，单个请求可能会被大量的并发请求同时触发。使用 SingleFlight 库可以让这些请求只触发一次，避免瞬间高并发带来的问题。  注意事项  在并发量不高的场景下，使用 SingleFlight 库可能会带来额外的开销。因此，在使用 SingleFlight 库时，需要根据实际场景权衡利弊。 在使用 SingleFlight 库时，需要确保传递给 Do 函数的 key 值唯一，否则可能会导致请求结果不符合预期。  优点  避免重复的计算和查询，减少了不必要的性能开销。 减少数据库和其他外部资源的负载，避免了由此产生的性能问题。 以避免竞态条件的发生，保证了程序的正确性和稳定性。  缺点  由于 SingleFlight 库需要维护一个请求池，因此在并发量较小的场景下，可能会带来额外的开销。 SingleFlight 库适用于高并发读场景，但不适用于高并发写场景。 一旦结果返回err，则全部的请求都会返回err。  改进 针对第三个缺点，我认为可以在Do和DoChan结构增加一个重试次数的参数，一旦此调用返回err，则继续重试，防止上述情况的发生。
]]></content></entry><entry><title>go整洁架构简单模板</title><url>/post/best-clean.html</url><categories><category>最佳实践</category></categories><tags><tag>go</tag><tag>整洁架构</tag></tags><content type="html"><![CDATA[在日常开发中，我们大多的精力都花在业务开发上，设计可能只占用了少部分的时间。 实际上，好的架构会让别人维护起来很舒服，很轻松。而不好的设计，会浪费你更多的时间，提高成本。 近些年来，整洁架构，领域驱动设计特别火，很多程序员也都用上了。 接下来，我将基于实际开发，介绍go使用整洁架构的例子。
分层设计 分层设计相信大家都知道，最熟悉的应该就是MVC（Model-View-Controller）架构了，分层能带来许多好处，它能解决各模块的依赖，且有很好的扩展性，对于越来越复杂的业务，如果没有任何设计，后期将难以维护。 这里，我介绍下我项目基于整洁架构的分层设计，这是目录结构：
├─api │ ├─dto │ └─handler ├─cmd ├─config ├─data ├─entity ├─test └─usecase 这个是最简单的结构，在实际业务开发中，可能还有日志，监控等其他模块，可以再增加pkg目录，然后通过wire注入依赖。 整体的架构大概是这样： 模块介绍 下面我将基于目录结构介绍各个模块
api api是架构图的右侧部分，起数据传递的功能，将输入的数据转化成entity的格式，转发usecase处理后将entity转换成业务需要的数据。 其中，dto（Data Transfer Object）是外部输入输出（http，grpc）的数据结构，handler是处理dto跟entity的相互转化，并转发到usecase处理业务逻辑 （这一层也可以做基本的数据校验，required，lte等等）。
func (h *Order) orderCreate(w http.ResponseWriter, r *http.Request) { // 处理输入  var req dto.OrderCreateReq if err := json.NewDecoder(r.Body).Decode(&amp;req); err != nil { http.Error(w, err.Error(), http.StatusBadRequest) } // 转发usecase  id, err := h.order.CreateOrder(r.Context(), transCreateReqToOrder(&amp;req), transCreateReqToPay(&amp;req)) if err != nil { http.Error(w, err.Error(), http.StatusInternalServerError) } // 处理输出  reply := &amp;dto.OrderCreateReply{OrderID: id} w.Header().Set(&#34;Content-Type&#34;, &#34;application/json&#34;) json.NewEncoder(w).Encode(reply) } 实际开发中，handler会有很多重复代码，可以利用反射，或者自动化生成代码减少重复性的工作。
cmd cmd是项目的入口，主要是做初始化工作，依赖注入，程序的启动，优雅退出。
func main() { c := config.New() d, err := data.NewData(c.DB) if err != nil { panic(err) } orderRepo := data.NewOrderRepo(d) payRepo := data.NewPayRepo(d) tm := data.NewTransaction(d) uc := usecase.NewOrder(orderRepo, payRepo, tm) orderHandler := handler.NewOrder(uc) s := api.NewServer(c.Server, orderHandler) if err = s.Run(); err != nil { panic(err) } } config 存放配置文件，可能是json，yaml或者配置中心等等都可以，根据实际项目选择最合适的，主要工作是配置解析。
func New() *Config { // TODO Config init from file 	return &amp;Config{ Server: &amp;Server{ Addr: &#34;:8080&#34;, }, DB: &amp;DB{ Driver: &#34;mysql&#34;, Source: &#34;root:123456@tcp(127.0.0.1:3306)/testDB&#34;, }, } } data data是repo接口的实现，主要是数据库的curd，或者是其他微服务的调用，项目里我只展示数据库的操作。
type Data struct { db *sql.DB } func NewData(conf *config.DB) (*Data, error) { db, err := sql.Open(conf.Driver, conf.Source) if err != nil { return nil, err } defer func() { _ = db.Close() }() return &amp;Data{ db: db, }, nil } 接口的实现
type payRepo struct { data *Data } func NewPayRepo(data *Data) usecase.PayRepo { return &amp;payRepo{data: data} } func (payRepo) CreatePay(ctx context.Context, pay *entity.Pay) (int64, error) { //TODO implement me 	panic(&#34;implement me&#34;) } func (payRepo) DeletePayByID(ctx context.Context, i int64) error { //TODO implement me 	panic(&#34;implement me&#34;) } 针对跨repo的事务下面会详细介绍。
entity entity层主要定义的各个领域的业务对象，这些结构是共用的，handler，usecase，data都是使用entity所定义的结构进行通讯。 所以应该根据自己的实际业务需要，定义好自己的实体结构（并不是简单的根据表结构去定义）。
type Order struct { ID int64 `json:&#34;id&#34;` OrderNo string `json:&#34;order_no&#34;` // 订单编号  OrderStatus int `json:&#34;order_status&#34;` // 订单状态 0未付款,1已付款,2已发货,3已签收,-1退货申请,-2退货中,-3已退货,-4取消交易  ProductCount int64 `json:&#34;product_count&#34;` // 商品数量  ProductAmount float64 `json:&#34;product_amount&#34;` // 商品总价  OrderAmount float64 `json:&#34;order_amount&#34;` // 实际付款金额  PayTime time.Time `json:&#34;pay_time&#34;` // 付款时间  DeliveryTime time.Time `json:&#34;delivery_time&#34;` // 发货时间  CreatedAt time.Time `json:&#34;created_at&#34;` UpdatedAt time.Time `json:&#34;updated_at&#34;` } test test 这个目录，主要是对整个链路的测试，如http，grpc等等，而单元测试还是按照go官方的形式，放在自己项目下，用mock生成接口，具体可以看我之前写的单元测试的blog。
### Get Order GET http://127.0.0.1:8080/order?id=1 ### Create Order POST http://127.0.0.1:8080/order Content-Type: application/json { &#34;value&#34;: &#34;content&#34; } ### Update Order PUT http://127.0.0.1:8080/order ### Delete Order DELETE http://127.0.0.1:8080/order usecase usecase主要是业务逻辑的实现，输入输出统一用entity层的结构。
type OrderUseCase struct { order OrderRepo pay PayRepo tm Transaction } func NewOrder(order OrderRepo, pay PayRepo, tm Transaction) *OrderUseCase { return &amp;OrderUseCase{ order: order, pay: pay, tm: tm, } } func (uc *OrderUseCase) CreateOrder(ctx context.Context, order *entity.Order, pay *entity.Pay) (orderID int64, err error) { err = uc.tm.InTx(ctx, func(ctx context.Context) error { if orderID, err = uc.order.CreateOrder(ctx, order); err != nil { return err } if _, err = uc.pay.CreatePay(ctx, pay); err != nil { return err } return nil }) return } 这一层不会有依赖，有依赖都使用interface，测试都用mock生成。
type OrderRepo interface { CreateOrder(context.Context, *entity.Order) (int64, error) FindOrderByID(context.Context, int64) (*entity.Order, error) UpdateOrderByID(context.Context, *entity.Order, int64) error DeleteOrderByID(context.Context, int64) error } type PayRepo interface { CreatePay(context.Context, *entity.Pay) (int64, error) DeletePayByID(context.Context, int64) error } 事务 关于整洁架构，有时候我们需要在多个repo开启事务，如何实现呢，这里我推荐一个比较优雅的办法，也是最多人使用的。 首先我们可以定义我们的事务接口：
type Transaction interface { InTx(context.Context, func(ctx context.Context) error) error } 输入是context和执行事务的函数，输出是error，实现通过data实现
func NewTransaction(d *Data) usecase.Transaction { return d } func (d *Data) InTx(ctx context.Context, fn func(ctx context.Context) error) error { tx, err := d.db.Begin() if err != nil { return err } defer func() { _ = tx.Rollback() }() err = fn(context.WithValue(ctx, contextTxKey{}, tx)) if err != nil { return err } return tx.Commit() } 而我们repo的实现统一使用data的DB函数返回DbTx去跟数据库交互
type DbTx interface { QueryRowContext(ctx context.Context, query string, args ...any) *sql.Row QueryContext(ctx context.Context, query string, args ...any) (*sql.Rows, error) ExecContext(ctx context.Context, query string, args ...any) (sql.Result, error) } func (d *Data) DB(ctx context.Context) DbTx { tx, ok := ctx.Value(contextTxKey{}).(*sql.Tx) if ok { return tx } return d.db } 这样一来，我们就可以轻松实现跨repo的事务，而且，repo的实现不用去考虑事务的东西，事务完全是由外部去控制。
总结 说了这么多，总结以下整洁架构的优缺点，如果你觉得合适，才能用在项目中，切勿无脑使用。
优点  可扩展，每一层都是单一职责，不相互依赖，业务增长时，项目不易腐烂，具有很好的扩展性。 可测试，可以利用mock在没有依赖时轻松测试自己的业务逻辑。 可迁移，项目使用了interface抽象，可以轻松迁移框架，或者数据库等等。  缺点  复杂，这是一个相对复杂的架构，需要你对自己的业务有很好的理解，不熟悉业务会对领域的拆分，实体的结构定义可能会不准确，后续只会增加你的额外工作。 适用场景，如果你的项目比较简单，稳定，建议使用传统的MVC架构，该架构并不适用简单的CURD项目。  项目地址  https://github.com/lemon-1997/clean  
]]></content></entry><entry><title>go自动化生成数据库curd代码（五）：面向接口编程</title><url>/post/project-sqlboy-5.html</url><categories><category>项目实战</category></categories><tags><tag>go</tag><tag>generate</tag><tag>sqlboy</tag><tag>设计模式</tag></tags><content type="html"><![CDATA[上一节过后，我们已经完成了所有代码的生成工作，最后的任务就是将解析，生成的模块全部集成在一起，并对外提供命令行调用（cmd）。
抽象接口 在编写代码之前，我的第一个工作，就是针对解析以及生成模块，抽象出两大类接口，解析的以及生成的接口。 这是因为，我的主逻辑不能够依赖底层的模块，而是依赖定义的接口，这样能更好维护项目，且达到解耦的目的，而我的底层模块只需要关注自己的职责，不关注上层的调用。
type Parser interface { Name() string Parse(interface{}) (interface{}, error) } type Generator interface { Name() string Generate(interface{}) (*bytes.Buffer, error) } 由于AST和ANTRL的输入和输出不确定，所以对Parser的抽象的入参和出参都是interface{}，ANTRL的实现如下，我们需要定义输入输出方便外部调用
type AntlrParseIn struct { Stmt string } type AntlrParseOut struct { antlrParser.TableAttr } type AntlrParser struct{} func (*AntlrParser) Name() string { return &#34;AntlrParser&#34; } func (*AntlrParser) Parse(in interface{}) (interface{}, error) { parseIn, ok := in.(AntlrParseIn) if !ok { return nil, errors.New(&#34;parse in type error&#34;) } attr, errs := parseStmt(parseIn.Stmt) if len(errs) != 0 { return nil, errs[0] } return AntlrParseOut{TableAttr: attr}, nil } Generator只有输入定义为interface{}，输出可以都定义为*bytes.Buffer，因为最后都是需要生成文件。 这里实现的代码就不贴了，和上面的类似。
事件总线 有了第一步的抽象，我发现解析以及生成模块数量比较多，如果要将他们集成在一起，主逻辑会变得复杂臃肿，模块调用之间相互依赖，后期新增删减模块将会异常恶心。 于是这里使用了事件总线（看到ANTLR runtime包受到的启发），事件总线是发布订阅的一种实现，允许不同的组件之间进行彼此通信而又不需要相互依赖，达到一种解耦的目的。 我参考了网上的go事件总线代码，利用反射去实现，而且是异步，性能高
type Topic string type Bus interface { Subscribe(topic Topic, handler interface{}) error Publish(topic Topic, args ...interface{}) } type AsyncEventBus struct { handlers map[Topic][]reflect.Value lock sync.Mutex } func NewAsyncEventBus() *AsyncEventBus { return &amp;AsyncEventBus{ handlers: map[Topic][]reflect.Value{}, lock: sync.Mutex{}, } } func (bus *AsyncEventBus) Subscribe(topic Topic, f interface{}) error { bus.lock.Lock() defer bus.lock.Unlock() v := reflect.ValueOf(f) if v.Type().Kind() != reflect.Func { return errors.New(&#34;handler is not a function&#34;) } handler, ok := bus.handlers[topic] if !ok { handler = []reflect.Value{} } handler = append(handler, v) bus.handlers[topic] = handler return nil } func (bus *AsyncEventBus) Publish(topic Topic, args ...interface{}) { handlers, ok := bus.handlers[topic] if !ok { fmt.Println(&#34;not found handlers in topic:&#34;, topic) return } params := make([]reflect.Value, len(args)) for i, arg := range args { params[i] = reflect.ValueOf(arg) } for i := range handlers { go handlers[i].Call(params) } } 有了对解析，生成的抽象以及事件总线后，我们就可以开始编写主逻辑了。
主逻辑 先定义我们的结构
type Boy struct { file string // sql定义文件路径  mode GenMode // 生成代码模式 gorm/sqlx  genPackage string // 生成包名  bus *bus.AsyncEventBus // 事件总线  err chan error // 错误信号  done chan struct{} // 完成信号  data chan interface{} // 数据信号 } 在New结构体时使用了optional设计模式，方便后续新增参数
type Option func(*Boy) func Mode(mode GenMode) Option { return func(boy *Boy) { boy.mode = mode } } func NewBoy(filePath string, opts ...Option) *Boy { boy := &amp;Boy{ file: filePath, mode: ModeGorm, err: make(chan error), done: make(chan struct{}), data: make(chan interface{}, 10), } for _, opt := range opts { opt(boy) } boy.register() return boy } 事件总线初始化
func (b *Boy) register() { eventBus := bus.NewAsyncEventBus() _ = eventBus.Subscribe(TopicAstParse, b.eventAstParse) _ = eventBus.Subscribe(TopicAntlrParse, b.eventAntlrParse) _ = eventBus.Subscribe(TopicAssertGenerate, b.eventAssertGenerate) _ = eventBus.Subscribe(TopicModelGenerate, b.eventModelGenerate) _ = eventBus.Subscribe(TopicDaoGenerate, b.eventDaoGenerate) _ = eventBus.Subscribe(TopicTxGenerate, b.eventTxGenerate) _ = eventBus.Subscribe(TopicQueryGenerate, b.eventQueryGenerate) b.bus = eventBus } 相对应的解析和生成函数，parse如果解析成功则会发数据，失败则会发错误的信号，generate如果生成成功则会生成文件，生成后发送完成的信号，反之则发错误的信号。
func (b *Boy) parse(parser inter.Parser, in interface{}) { res, err := parser.Parse(in) if err != nil { b.err &lt;- fmt.Errorf(&#34;%s:%w&#34;, parser.Name(), err) return } b.data &lt;- res } func (b *Boy) generate(gen inter.Generator, in interface{}, file string) { buf, err := gen.Generate(in) if err != nil { b.err &lt;- fmt.Errorf(&#34;%s:%w&#34;, gen.Name(), err) return } source, err := format.Source(buf.Bytes()) if err != nil { b.err &lt;- fmt.Errorf(&#34;%s:%w&#34;, gen.Name(), err) return } if err = os.WriteFile(b.genPath(file), source, 0664); err != nil { b.err &lt;- fmt.Errorf(&#34;%s:%w&#34;, gen.Name(), err) return } b.done &lt;- struct{}{} } 然后是主逻辑，主要处理数据信号，错误信号以及完成信号，可以看到有了事件总线后代码更加清晰，而且异步效率更高。
func (b *Boy) Do() error { b.bus.Publish(TopicAstParse) var genTables, genCount int tables := make(map[string][]parserAntlr.ColumnDecl) for { select { case data := &lt;-b.data: switch data.(type) { case parser.AstParseOut: res := data.(parser.AstParseOut) genTables = len(res.Stmt) b.genPackage = res.PackageName b.bus.Publish(TopicDaoGenerate) b.bus.Publish(TopicTxGenerate) b.bus.Publish(TopicAssertGenerate, res.Stmt) for _, stmt := range res.Stmt { s, err := strconv.Unquote(stmt) if err != nil { return err } b.bus.Publish(TopicAntlrParse, s) } case parser.AntlrParseOut: res := data.(parser.AntlrParseOut) tables[res.TableName] = res.Columns b.bus.Publish(TopicQueryGenerate, b.transRenderData(res)) if len(tables) == genTables { b.bus.Publish(TopicModelGenerate, tables) } } case &lt;-b.done: genCount++ // assert,model,dao,tx is 4 file 	if genCount &gt;= genTables+4 { return nil } case err := &lt;-b.err: return err default: continue } } } cmd 完成主逻辑后，就到我们的命令了，我们规定至少要有一个参数，就是SQL的文件路径，然后只有mode一个选项，默认是生成gorm代码。
const ( usage = `sqlboy [packages] sqlboy $path -mode gorm Find more information at: https://github.com/lemon-1997/sqlboy ` ) func main() { log.SetFlags(0) log.SetPrefix(&#34;sqlboy:&#34;) if len(os.Args) &lt; 2 { log.Fatal(&#34;no specify file&#34;) } flag.Usage = func() { fmt.Print(usage) flag.PrintDefaults() } flag.Parse() var mode string fs := flag.NewFlagSet(&#34;sqlboy&#34;, flag.ExitOnError) fs.StringVar(&amp;mode, &#34;mode&#34;, &#34;&#34;, &#34;gorm or sqlx&#34;) _ = fs.Parse(os.Args[2:]) var opts []sqlboy.Option if mode != &#34;&#34; { genMode := sqlboy.GenMode(mode) if genMode != sqlboy.ModeGorm &amp;&amp; genMode != sqlboy.ModeSqlx { log.Fatalf(&#34;mode %s is not gorm or sqlx&#34;, mode) } opts = append(opts, sqlboy.Mode(genMode)) } boy := sqlboy.NewBoy(os.Args[1], opts...) err := boy.Do() if err != nil { log.Fatal(err) } log.Printf(&#34;generate success&#34;) os.Exit(0) } 测试 先安装命令
go install github.com/lemon-1997/sqlboy/cmd/sqlboy@latest 创建我们的文件，stmt.go，文件内容如下
const ( order = ` -- order_info definition CREATE TABLE &#39;order_info&#39; ( &#39;id&#39; int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT &#39;自增ID&#39;, &#39;order_id&#39; varchar(20) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;订单号&#39;, &#39;status&#39; tinyint(3) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;订单状态&#39;, &#39;created_at&#39; timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;, &#39;updated_at&#39; timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#39;修改时间&#39;, PRIMARY KEY (&#39;id&#39;), UNIQUE KEY &#39;uk_order&#39; (&#39;order_id&#39;) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT=&#39;订单表&#39;; ` product = ` -- product_info definition CREATE TABLE &#39;product_info&#39; ( &#39;id&#39; int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT &#39;自增ID&#39;, &#39;product_id&#39; varchar(20) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;商品编号&#39;, &#39;sku_id&#39; varchar(20) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;sku&#39;, &#39;status&#39; tinyint(3) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;商品状态&#39;, &#39;created_at&#39; timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;, &#39;updated_at&#39; timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#39;修改时间&#39;, PRIMARY KEY (&#39;id&#39;), UNIQUE KEY &#39;uk_product&#39; (&#39;product_id&#39;, &#39;sku_id&#39;) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT=&#39;商品表&#39;; ` ) 生成gorm代码
sqlboy ./stmt.go -mode gorm 生成sqlx代码
sqlboy ./stmt.go -mode sqlx 小结 终于完成了项目和blog的更新，很开心，不过这个系列五篇blog更新的比较仓促，写的匆忙，有许多地方没有写好，因为接下来我有其他事，所以不得不连续五天更新把这个系列完结。 如果对sqlboy感兴趣的话，也欢迎大家使用，有问题可以在github提issue，感谢观看。
项目源码：https://github.com/lemon-1997/sqlboy
]]></content></entry><entry><title>go自动化生成数据库curd代码（四）：模板生成</title><url>/post/project-sqlboy-4.html</url><categories><category>项目实战</category></categories><tags><tag>go</tag><tag>generate</tag><tag>sqlboy</tag><tag>template</tag></tags><content type="html"><![CDATA[上一节我们完成了对SQL的解析，得到了表的相关信息。根据这些信息，我们就可以确定表相对应的curd代码，生成代码我们使用go自带的标准包text/template。 下面将为大家介绍template，并使用template实现代码生成功能。
template使用 模板数据 下面的例子，执行完会输出10 items
type Data struct { Count uint } tmpl, err := template.New(&#34;test&#34;).Parse(&#34;{{.Count}} items&#34;) if err != nil { panic(err) } err = tmpl.Execute(os.Stdout, Data{Count: 10}) if err != nil { panic(err) } 模板里{{.Count}}指的从当前对象取Count变量，其中.指的就是当前对象，也就是我们传入的Data对象，所以最终{{.Count}}会被替换成10，这也是最基础的用法。
空白去除 假设有以下模板
&#34;{{23 -}} &lt; {{- 45}}&#34; 最终的结果是
&#34;23&lt;45&#34; -}}与{{-是template规定的一种语法，-}}表示去除后面的空格，反之同理。去除空白是一个很实用的功能，后面我将利用他去除多余的空行。 如果没有这个功能，我们的模板文件将会变得很拥挤，难以维护。所以，要多利用去除空白，让我们的模板变得更清晰。
常用的Action 介绍两个比较常用的，一个是条件判断
{{if pipeline}} T1 {{else if pipeline}} T0 {{end}} 另一个是遍历，这里要注意的是作用域的问题，range里面的作用域{{.}}实际上是你遍历的对象，而不再是顶层的渲染对象。
{{range pipeline}} T1 {{end}} 这两个都比较简单，后面会使用到。
变量 我们还可以在模板定义我们的变量
$variable := pipeline $variable = pipeline range $index, $element := pipeline 函数 template有内置函数供我们使用，以下摘自go官方文档
and Returns the boolean AND of its arguments by returning the first empty argument or the last argument. That is, &#34;and x y&#34; behaves as &#34;if x then y else x.&#34; Evaluation proceeds through the arguments left to right and returns when the result is determined. call Returns the result of calling the first argument, which must be a function, with the remaining arguments as parameters. Thus &#34;call .X.Y 1 2&#34; is, in Go notation, dot.X.Y(1, 2) where Y is a func-valued field, map entry, or the like. The first argument must be the result of an evaluation that yields a value of function type (as distinct from a predefined function such as print). The function must return either one or two result values, the second of which is of type error. If the arguments don&#39;t match the function or the returned error value is non-nil, execution stops. html Returns the escaped HTML equivalent of the textual representation of its arguments. This function is unavailable in html/template, with a few exceptions. index Returns the result of indexing its first argument by the following arguments. Thus &#34;index x 1 2 3&#34; is, in Go syntax, x[1][2][3]. Each indexed item must be a map, slice, or array. slice slice returns the result of slicing its first argument by the remaining arguments. Thus &#34;slice x 1 2&#34; is, in Go syntax, x[1:2], while &#34;slice x&#34; is x[:], &#34;slice x 1&#34; is x[1:], and &#34;slice x 1 2 3&#34; is x[1:2:3]. The first argument must be a string, slice, or array. js Returns the escaped JavaScript equivalent of the textual representation of its arguments. len Returns the integer length of its argument. not Returns the boolean negation of its single argument. or Returns the boolean OR of its arguments by returning the first non-empty argument or the last argument, that is, &#34;or x y&#34; behaves as &#34;if x then x else y&#34;. Evaluation proceeds through the arguments left to right and returns when the result is determined. print An alias for fmt.Sprint printf An alias for fmt.Sprintf println An alias for fmt.Sprintln urlquery Returns the escaped value of the textual representation of its arguments in a form suitable for embedding in a URL query. This function is unavailable in html/template, with a few exceptions. 不仅如此，还支持我们自定义函数，这个下面将会讲到，有了自定义函数，模板渲染也将变得更加灵活。
模板定义 我们还可以定义我们的模板（定义不会输出）
{{define &#34;T1&#34;}}ONE{{end}} 使用定义的模板（输出模板T1定义的内容）
{{template &#34;T1&#34;}} 了解了template的基本语法后，就可以开发了。
静态文件 我把生成的文件分成静态和动态，静态是指不依赖数据表，文件内容始终一样的，只有包名是不确定，需要我们传入。 静态有dao.go以及transaction.go文件，先把渲染函数实现。
func render(tmpl string, wr io.Writer, data interface{}) error { t, err := template.New(tmpl).Parse(tmpl) if err != nil { return err } return t.Execute(wr, data) } 而我们的模板只有一处是变化的，就是包名package {{.}}，我们直接用{{.}}，所以渲染的调用方式类似下面这样
var packageName string var buf bytes.Buffer err := render(tmpl, &amp;buf, packageName) if err != nil{ return err } 动态文件 动态文件在这里只有curd代码，表对应的结构体代码已经交给AST生成，这里就不再说了，只讲template部分。 由于curd代码比较复杂，所以我们需要用到自定义函数，自定义函数是这样使用的
funcMap := template.FuncMap{ &#34;caseExport&#34;: camelCaseExport, &#34;caseInternal&#34;: camelCaseInternal, } t, err := template.New(tmpl).Funcs(funcMap).Parse(tmpl) if err != nil { return err } return t.Execute(wr, data) camelCaseExport，camelCaseInternal是我自定义的函数，功能是把变量转化成驼峰命名，一个是可导出的命名（首字母大写），一个是内部的命名（首字母小写）。 在模板文件中，可以直接调用自定义函数
{{- $tableExport := caseExport .Table -}} {{- $tableInternal := caseInternal .Table -}} 这里定义了两个变量，分别是表名的导出命名和内部命名，后续直接引用变量就行。在编写模板文件时，难点在于需要生成主键，以及唯一键的curd代码。 我们可以先定义好渲染的变量
type Column struct { Name string Type string IsNotNull bool } type QueryData struct { Package string Table string Columns []Column PrimaryKey []Column UniqueKeys [][]Column ImportSqlx bool } 以唯一键为例，我们需要遍历，表中定义的唯一键
// keyFunSign表示遍历传入的唯一键，并将其变成导出命名，比如我们有一组唯一键（`id`, `count`），那么将会变成：IdCount {{- define &#34;keyFunSign&#34; -}} {{range .}}{{caseExport .Name}}{{end}} {{- end -}} // keyParams表示遍历传入的唯一键，比如我们有一组唯一键（`id`, `count`），将会生成：, id int64, count int64 {{- define &#34;keyParams&#34; -}} {{range .}}, {{caseInternal .Name}} {{.Type}}{{end}} {{- end -}} {{- range .UniqueKeys}} FindBy{{template &#34;keyFunSign&#34; .}}(ctx context.Context{{template &#34;keyParams&#34; .}}) (*{{$tableExport}}, error) UpdateBy{{template &#34;keyFunSign&#34; .}}(ctx context.Context, {{$tableInternal}} *{{$tableExport}}) error DeleteBy{{template &#34;keyFunSign&#34; .}}(ctx context.Context{{template &#34;keyParams&#34; .}}) error {{- end}} 其他的过程都大同小异，只不过生成sqlx代码会复杂点，因为存在null特殊结构，而且还需要拼接sql，不过也差不多，花点时间加上自定义函数的帮助也能够实现，这里就不再展开描述。
小结 在这节过后，我们已经完成了90%的工作，所以的模块，功能已经实现。剩下的任务就是将这些模块拼接，集成使用，由于模块比较分散，组装也不是件容易的事，这个我会在下一篇文章讲到。
项目源码：https://github.com/lemon-1997/sqlboy
]]></content></entry><entry><title>go自动化生成数据库curd代码（三）：ANTLR解析SQL</title><url>/post/project-sqlboy-3.html</url><categories><category>项目实战</category></categories><tags><tag>go</tag><tag>generate</tag><tag>sqlboy</tag><tag>ANTLR</tag></tags><content type="html"><![CDATA[在上一节我们了解了go的抽象语法树AST，并利用go提供的AST包拿到了用户定义的sql。接下来就是如何解析sql，将sql语句中的表名，列字段的名称，类型等关键信息提取出来。 这就需要我们的语法分析了，在本项目中我们决定采用ANTLR来完成此任务，他是一个强大的工具，下文我将为大家介绍是如何实现的。
ANTLR 简介 再讲ANTLR之前，还是想先提一下yacc。yacc是比较出名的语法分析器，不过年代久远，诞生于上个世纪70年代，yacc需要与lex一起才能实现完整的语法树构建。 lex是词法分析器，用于分割语句中的词块，也就是token。go官方也提供了goyacc给我们使用，网上也有关于yacc解析sql的源码。 不过我们还是选择了使用更多的ANTLR，ANTLR目前仍在维护，实现起来比较简单，开发快，还支持所有主流语言，还提供了可视化的语法树，debug特别方便。
安装 安装ANTLR有两种方式，最简单的是用pip3安装。因为我本机有python3，所以很方便。
$ pip install antlr4-tools 执行命令
$ antlr4 Downloading antlr4-4.11.1-complete.jar ANTLR tool needs Java to run; install Java JRE 11 yes/no (default yes)? y Installed Java in /Users/parrt/.jre/jdk-11.0.15+10-jre; remove that dir to uninstall ANTLR Parser Generator Version 4.11.1 -o ___ specify output directory where all output is generated -lib ___ specify location of grammars, tokens files ... 如果上面的命令都没问题，就是安装成功了，我们可以尝试下，比如实现一个计算器。 先创建Expr.g4，文件名必须与grammar相对应
grammar Expr;	prog:	expr EOF ; expr:	expr (&#39;*&#39;|&#39;/&#39;) expr |	expr (&#39;+&#39;|&#39;-&#39;) expr |	INT |	&#39;(&#39; expr &#39;)&#39; ; NEWLINE : [\r\n]+ -&gt; skip; INT : [0-9]+ ; 并使用强大的gui功能（语法树）
antlr4-parse Expr.g4 prog -gui 解析SQL 在编写规则的时候，本来是花了几天时间去实现，完成了表名以及id的定义，不过最后还是发现单单一个建表语句就有很多的规则。 如果单靠自己实现，可能会覆盖不全，而且我平时上班，可能需要花一个月的时间，写这个对我来说帮助也不是很大。 所以，我参照了ANTLR官方mysql的语法（ANTLR官方提供了大量的例子，有兴趣的可以去看看），稍微改造了下，只留下了建表的语法，其余的全部被我删除。 不过，lexer那里还是全部保留下来，虽然有很多token没有使用，考虑涉及到关键字的匹配分词，我都没删。 官方提供的语法虽然很牛逼，不过还是有好几个bug（有些规则为了复用，导致一些根本不会出现在建表规则的也匹配到了），不过这倒不影响，我们的功能要求是能解析，你只要能把正确的解析出来就行。 但是这里也不是说直接拷贝过来就完事，还是要考虑几个问题，解析是不支持多条语句的，如果多个表定义多个变量，分多次解析就行，表名也要支持db.tbl这种情况，mysql字段类型go中类型的转化问题，这些问题我都交给了运行时去解决。
运行时解析 先定义我们解析的结果
type ColumnDecl struct { Decl string // sql字段定义，用于debug  Name string // 字段名称  Comment string // 字段描述  SqlType string // mysql中的类型  GoType GoType // go中对应的类型  IsNotNull bool // 是否可以为空（sqlx有Null类型） } // 索引（用于生成curd代码的查询条件） type ColumnIndex struct { Decl string Columns []ColumnDecl } type TableAttr struct { TableName string // 表名  Columns []ColumnDecl // 字段  PrimaryKey ColumnIndex // 主键  UniqueKeys []ColumnIndex // 唯一键 } GoType的定义
type GoType string const ( Invalid = &#34;invalid&#34; Bool = &#34;bool&#34; Int8 = &#34;int8&#34; Int16 = &#34;int16&#34; Int32 = &#34;int32&#34; Int64 = &#34;int64&#34; Uint8 = &#34;uint8&#34; Uint16 = &#34;uint16&#34; Uint32 = &#34;uint32&#34; Uint64 = &#34;uint64&#34; Float32 = &#34;float32&#34; Float64 = &#34;float64&#34; String = &#34;string&#34; Time = &#34;time.Time&#34; SliceByte = &#34;[]byte&#34; SliceUint8 = &#34;[]uint8&#34; ) 定义好解析结果后，我们先用ANTLR生成代码
antlr4 -Dlanguage=Go *.g4 生成之后，我们实现自己的listener
type StmtListener struct { *BaseStmtParserListener column ColumnDecl TableAttr } func NewStmtListener() *StmtListener { return new(StmtListener) } 代码比较长，这里以提取表名为例子
func (l *StmtListener) EnterTableName(ctx *TableNameContext) { var tableName string switch ctx.GetStop().GetTokenType() { // 需要去掉引号  case StmtParserREVERSE_QUOTE_ID, StmtParserCHARSET_REVERSE_QOUTE_STRING, StmtParserSTRING_LITERAL: name := ctx.GetStop().GetText() if len(name) &lt;= 2 { return } tableName = name[1 : len(name)-1] // db.tbl的形式  case StmtParserDOT_ID: name := ctx.GetStop().GetText() if len(name) &lt;= 1 { return } tableName = name[1:] default: tableName = ctx.GetText() } l.TableName = tableName } 除了解析之外，我们还需要对错误进行处理，不然错误发生我们都还不知道，无法判断SQL是否正确
type ErrorListener struct { *antlr.DefaultErrorListener errors []error } func NewErrorListener() *ErrorListener { return new(ErrorListener) } func (l *ErrorListener) HasError() bool { return len(l.errors) &gt; 0 } func (l *ErrorListener) Errors() []error { return l.errors } func (l *ErrorListener) SyntaxError(recognizer antlr.Recognizer, offendingSymbol interface{}, line, column int, msg string, e antlr.RecognitionException) { p := recognizer.(antlr.Parser) stack := p.GetRuleInvocationStack(p.GetParserRuleContext()) err := fmt.Errorf(&#34;rule: %v line %d: %d at %v : %s&#34;, stack[0], line, column, offendingSymbol, msg) l.errors = append(l.errors, err) } 随后便将上面两个集成在一起使用
import ( &#34;github.com/antlr/antlr4/runtime/Go/antlr/v4&#34; parser &#34;github.com/lemon-1997/sqlboy/antlr&#34; ) func parseStmt(ddl string) (parser.TableAttr, []error) { input := antlr.NewInputStream(ddl) lexer := parser.NewStmtLexer(input) stream := antlr.NewCommonTokenStream(lexer, 0) p := parser.NewStmtParser(stream) el := parser.NewErrorListener() p.RemoveErrorListeners() p.AddErrorListener(el) p.BuildParseTrees = true tree := p.Prog() if el.HasError() { return parser.TableAttr{}, el.Errors() } l := parser.NewStmtListener() antlr.ParseTreeWalkerDefault.Walk(l, tree) return l.TableAttr, nil } 在实现代码过程中，还发现了ANTLR go runtime包的一个错误，并提了个pr https://github.com/antlr/antlr4/pull/3999  
小结 好了，到这里我们已经能够正确把SQL解析，并提取出我们想要的表字段等信息，有了这些信息后，我们就可以根据表的结构，去生成相应的代码了。 下一节我将向大家介绍如果用模板渲染出代码，有兴趣的可以关注一下。
项目源码：https://github.com/lemon-1997/sqlboy
]]></content></entry><entry><title>go自动化生成数据库curd代码（二）：go抽象语法树（AST）</title><url>/post/project-sqlboy-2.html</url><categories><category>项目实战</category></categories><tags><tag>go</tag><tag>generate</tag><tag>sqlboy</tag><tag>AST</tag></tags><content type="html"><![CDATA[在上一篇文章中，介绍了我对这个项目的想法，总体设计与思路，而在项目中AST是一个很重要的模块，他主要负责输入的解析，还负责部分代码生成工作。 接下来，我将为大家介绍go中的抽象语法树，也会跟大家分享我是如何利用AST去实现功能的。
AST AST是go中的抽象语法树，许多代码生成工具，代码静态检测都离不开他。如果我们了解了AST，我们可以去实现一些好玩的东西。
go对节点的定义
// All node types implement the Node interface. type Node interface { Pos() token.Pos // position of first character belonging to the node 	End() token.Pos // position of first character immediately after the node } 主要有 3 类节点：Expr（表达式）, Stmt（语句）, Decl（声明）
// All expression nodes implement the Expr interface. type Expr interface { Node exprNode() } // All statement nodes implement the Stmt interface. type Stmt interface { Node stmtNode() } // All declaration nodes implement the Decl interface. type Decl interface { Node declNode() } 其中，我们着重要了解下Decl（声明节点），因为会经常用到，有三种Decl
// A declaration is represented by one of the following declaration nodes. type ( // A BadDecl node is a placeholder for a declaration containing 	// syntax errors for which a correct declaration node cannot be 	// created. 	// 	BadDecl struct { From, To token.Pos // position range of bad declaration 	} // A GenDecl node (generic declaration node) represents an import, 	// constant, type or variable declaration. A valid Lparen position 	// (Lparen.IsValid()) indicates a parenthesized declaration. 	// 	// Relationship between Tok value and Specs element type: 	// 	//	token.IMPORT *ImportSpec 	//	token.CONST *ValueSpec 	//	token.TYPE *TypeSpec 	//	token.VAR *ValueSpec 	// 	GenDecl struct { Doc *CommentGroup // associated documentation; or nil 	TokPos token.Pos // position of Tok 	Tok token.Token // IMPORT, CONST, TYPE, or VAR 	Lparen token.Pos // position of &#39;(&#39;, if any 	Specs []Spec Rparen token.Pos // position of &#39;)&#39;, if any 	} // A FuncDecl node represents a function declaration. 	FuncDecl struct { Doc *CommentGroup // associated documentation; or nil 	Recv *FieldList // receiver (methods); or nil (functions) 	Name *Ident // function/method name 	Type *FuncType // function signature: type and value parameters, results, and position of &#34;func&#34; keyword 	Body *BlockStmt // function body; or nil for external (non-Go) function 	} ) 通过注释我们可以大致得知，GenDecl用于表示import，const，type或变量声明，FunDecl用于表示函数声明。
那么，一个go文件会被抽象成什么样呢，下面是ast.File结构，后续也会经常用到
type File struct { Doc *CommentGroup // associated documentation; or nil 	Package token.Pos // position of &#34;package&#34; keyword 	Name *Ident // package name 	Decls []Decl // top-level declarations; or nil 	Scope *Scope // package scope (this file only) 	Imports []*ImportSpec // imports in this file 	Unresolved []*Ident // unresolved identifiers in this file 	Comments []*CommentGroup // list of all comments in the source file } 注释其实也解释的很清楚，有两个关键字段，一个是Name，用于我们提取包名，另外一个是Decls，const变量的声明。
有了该结构，思路也就来了，只要能拿到改结构体，事情就好办了，不过在开始写代码前，我们还要了解一下这个函数
func Inspect(node Node, f func(Node) bool) { Walk(inspector(f), node) } go官方怕我们对结构不熟悉，加上语法树层级复杂，嵌套的关系，这里贴心的帮我们实现了遍历的方法。 不过在这个项目我并没有用到，一个是我觉得遍历效率低，另一个是我的嵌套并不会很深，直接获取就行了。
处理输入 简单了解了AST后，我们就可以准备实现了。首先，我们定义我们的目标，一个是提取文件的包名，另一个是提取const变量以及对应的sql语句。 如何简单又快速的实现呢，这里推荐两种方法，一个是直接到 go AST viewer  网站上去看解析的结果，另一个是自己debug，将需要解析的文件AST抽象后看里面的结构。
假设我们有以下文件有解析
package sqlboy const ( order = ` -- order_info definition CREATE TABLE &#39;order_info&#39; ( &#39;id&#39; int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT &#39;自增ID&#39;, &#39;order_id&#39; varchar(20) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;订单号&#39;, &#39;status&#39; tinyint(3) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;订单状态&#39;, &#39;created_at&#39; timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;, &#39;updated_at&#39; timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#39;修改时间&#39;, PRIMARY KEY (&#39;id&#39;), UNIQUE KEY &#39;uk_order&#39; (&#39;order_id&#39;) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT=&#39;订单表&#39;; ` ) 经过抽象后
0 *ast.File { 1 . Doc: nil 2 . Package: foo:1:1 3 . Name: *ast.Ident { 4 . . NamePos: foo:1:9 5 . . Name: &#34;sqlboy&#34; 6 . . Obj: nil 7 . } 8 . Decls: []ast.Decl (len = 1) { 9 . . 0: *ast.GenDecl { 10 . . . Doc: nil 11 . . . TokPos: foo:3:1 12 . . . Tok: const 13 . . . Lparen: foo:3:7 14 . . . Specs: []ast.Spec (len = 1) { 15 . . . . 0: *ast.ValueSpec { 16 . . . . . Doc: nil 17 . . . . . Names: []*ast.Ident (len = 1) { 18 . . . . . . 0: *ast.Ident { 19 . . . . . . . NamePos: foo:4:2 20 . . . . . . . Name: &#34;order&#34; 21 . . . . . . . Obj: *ast.Object { 22 . . . . . . . . Kind: const 23 . . . . . . . . Name: &#34;order&#34; 24 . . . . . . . . Decl: *(obj @ 15) 25 . . . . . . . . Data: 0 26 . . . . . . . . Type: nil 27 . . . . . . . } 28 . . . . . . } 29 . . . . . } 30 . . . . . Type: nil 31 . . . . . Values: []ast.Expr (len = 1) { 32 . . . . . . 0: *ast.BasicLit { 33 . . . . . . . ValuePos: foo:4:10 34 . . . . . . . Kind: STRING 35 . . . . . . . Value: &#34;`\n-- order_info definition\n\nCREATE TABLE &#39;order_info&#39; (\n &#39;id&#39; int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT &#39;自增ID&#39;,\n &#39;order_id&#39; varchar(20) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;订单号&#39;,\n &#39;status&#39; tinyint(3) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;订单状态&#39;,\n &#39;created_at&#39; timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;,\n &#39;updated_at&#39; timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#39;修改时间&#39;,\n PRIMARY KEY (&#39;id&#39;),\n UNIQUE KEY &#39;uk_order&#39; (&#39;order_id&#39;)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT=&#39;订单表&#39;;\n`&#34; 36 . . . . . . } 37 . . . . . } 38 . . . . . Comment: nil 39 . . . . } 40 . . . } 41 . . . Rparen: foo:17:1 42 . . } 43 . } 44 . Scope: *ast.Scope { 45 . . Outer: nil 46 . . Objects: map[string]*ast.Object (len = 1) { 47 . . . &#34;order&#34;: *(obj @ 21) 48 . . } 49 . } 50 . Imports: nil 51 . Unresolved: nil 52 . Comments: nil 53 } 因此，我们可以写出以下解析代码
func parse(file *ast.File) (packageName string, ddl map[string]string) { if file == nil { return } if file.Name != nil { packageName = file.Name.Name } ddl = make(map[string]string) for _, decl := range file.Decls { genDecl, ok := decl.(*ast.GenDecl) if !ok { continue } if genDecl.Tok != token.CONST { continue } for _, spec := range genDecl.Specs { valueSpec, ok := spec.(*ast.ValueSpec) if !ok { continue } for i := range valueSpec.Names { value, ok := valueSpec.Values[i].(*ast.BasicLit) if !ok { continue } if value.Kind != token.STRING { continue } ddl[valueSpec.Names[i].Name] = value.Value } } } return } 这样一来，我们就实现了第一步对输入文件的解析，可能有的人会发现，上面的parse函数需要*ast.File结构，如何获得呢？
go已经帮我们实现好了，在$GOROOT/src/go/parser/interface.go
func ParseFile(fset *token.FileSet, filename string, src any, mode Mode) (f *ast.File, err error) 只需要提供文件路径，如果该文件没有语法错误的话，我们就能构建出*ast.File
编译时断言 在上一节说到，我们定义了输入的文件，建表的sql语句必须是const变量。这里我解释下，const主要是为了实现编译时断言。 什么是编译时断言呢，就是在编译时就能直接告诉你错误，无法编译通过。 许多自动化生成代码工具都会用到编译时断言，例如断言引用第三方库的版本，断言接口的实现，只要不符合，编译时就能及时发现，避免bug发生。
这里分享几个编译断言的技巧
 断言常量N不小于另一个常量M  func _(x []int) {_ = x[N-M]} func _(){_ = []int{N-M: 0}} func _([N-M]int){} var _ [N-M]int const _ uint = N-M type _ [N-M]int  断言两个整数常量相等  var _ [N-M]int; var _ [M-N]int type _ [N-M]int; type _ [M-N]int const _, _ uint = N-M, M-N func _([N-M]int, [M-N]int) {}  断言一个常量字符串是不是一个空串  type _ [len(aStringConstant)-1]int var _ = map[bool]int{false: 0, aStringConstant != &#34;&#34;: 1} var _ = aStringConstant[:1] var _ = aStringConstant[0] const _ = 1/len(aStringConstant)  断言字符串相等  const ( order = `order_info` product = `product_info` ) func _() { _ = map[bool]struct { }{false: {}, order == `order_info`: {}} _ = map[bool]struct { }{false: {}, product == `product_info`: {}} } 这个项目我用到了断言字符串相等，我保证了一旦建表语句sql被修改了，就必须重新生成断言文件，不然就无法编译通过。
确定了断言的方式之后，我们可以先看下断言文件对应的抽象语法树，然后再去编写代码，这里结构会复杂点，我就不放上来，直接贴实现的代码
func buildAssertAST(packageName string, paths, asserts map[string]string) *ast.File { importSpecs := make([]ast.Spec, 0) for name, path := range paths { importSpecs = append(importSpecs, &amp;ast.ImportSpec{ Name: ast.NewIdent(name), Path: &amp;ast.BasicLit{Kind: token.STRING, Value: path}, }) } maps := make([]*ast.CompositeLit, 0) for k, v := range asserts { elts := make([]ast.Expr, 0) elts = append(elts, &amp;ast.KeyValueExpr{ Key: ast.NewIdent(&#34;false&#34;), Value: &amp;ast.CompositeLit{}, }) elts = append(elts, &amp;ast.KeyValueExpr{ Key: &amp;ast.BinaryExpr{X: ast.NewIdent(k), Op: token.EQL, Y: &amp;ast.BasicLit{Kind: token.STRING, Value: v}}, Value: &amp;ast.CompositeLit{}, }) maps = append(maps, &amp;ast.CompositeLit{ Type: &amp;ast.MapType{Key: ast.NewIdent(&#34;bool&#34;), Value: &amp;ast.StructType{Fields: &amp;ast.FieldList{}}}, Elts: elts, }) } assignList := make([]ast.Stmt, 0) for _, item := range maps { assignList = append(assignList, &amp;ast.AssignStmt{ Lhs: []ast.Expr{ast.NewIdent(&#34;_&#34;)}, Tok: token.ASSIGN, Rhs: []ast.Expr{item}, }) } decls := make([]ast.Decl, 0) if len(paths) != 0 { decls = append(decls, &amp;ast.GenDecl{Tok: token.IMPORT, Specs: importSpecs}) } if len(asserts) != 0 { decls = append(decls, &amp;ast.FuncDecl{ Doc: &amp;ast.CommentGroup{List: []*ast.Comment{{Text: &#34;//compile-time assertion&#34;}}}, Name: ast.NewIdent(&#34;_&#34;), Type: &amp;ast.FuncType{}, Body: &amp;ast.BlockStmt{List: assignList}, }) } return &amp;ast.File{Name: ast.NewIdent(packageName), Decls: decls} } 到这里，我们不仅能解析用户的输入，还能构建出断言文件的抽象语法树。不过还差一步，就是将ast.File输出成.go文件。 当然，go也已经帮我们实现好了，在$GOROOT/src/go/format/format.go
func Node(dst io.Writer, fset *token.FileSet, node any) error 这里的参数是io.Writer，也就是你想输出到哪里都行，只要是实现了io.Writer的接口就行。
小结 到这里我们迈出了第一步，定义了输入的文件，并且通过AST将文件解析，提取出我们需要的东西，再将其生成编译时断言的文件。 不过这才刚刚开始，我们仅仅是实现了最简单的一部分，后面还有更难的要解决。下一篇文章是如何去实现对sql的解析，是关于ANTLR的，有兴趣的可以看一下。
项目源码：https://github.com/lemon-1997/sqlboy
]]></content></entry><entry><title>go自动化生成数据库curd代码（一）：想法与设计</title><url>/post/project-sqlboy.html</url><categories><category>项目实战</category></categories><tags><tag>go</tag><tag>generate</tag><tag>sqlboy</tag></tags><content type="html"><![CDATA[在平常业务开发中，我们经常会使用一些数据库框架，诸如gorm，sqlc，ent等等。 每当想新加一个表时，就会产生很多重复性的操作，例如插入数据，读取数据，删除之类。 这大大降低了开发效率，于是，我萌生了一个想法，想把这些操作都交给程序去实现。
想法 在有了这个想法之后，我根据实际业务需要，再结合一些优秀的开源项目后，我认为我的这个工具必须具备以下几个特点
 简单
一个是使用简单，代码生成的命令简单，没有复杂的参数，且输入只有sql建表语句。
另一个是生成的代码简单，可读，可靠，没有bug，尽量不生成冗余代码，使用者一目了然 。 全面
生成的代码要尽可能全面，覆盖到所有可能出现的场景。
本来我只想生成最基础的curd四个方法，后续又增加了批量插入，以及根据主键以及唯一键生成对于的查询，更新以及删除方法。 可用
可用的意思是即插即用，我生成的代码能立即被使用，无需做任何修改以及封装。
于是除了curd外，我还额外生成了dao，model，transaction等文件。  定义输入输出 输入 输入这里有两个选择，我纠结了好几天才做出的决定
 go文件：用go AST将建表sql读取解析。 配置文件：采用.yaml或者.json或者.sql的形式，然后读取配置文件。
利弊分析： 使用配置文件会比较优雅，好实现。 采用go ast读取实现较难，但是可以使用编译时断言。 最终为了学习下go AST，就不用简单的配置文件形式，而是采用后者。  输出 暂时决定有两种输出模式，一种是gorm，一种是sqlx，想生成哪种由用户决定。这里以sqlx为例，总共会生成以下文件：
 assert.go  package sqlboy func _() { _ = map[bool]struct { }{false: {}, order == ` -- order_info definition CREATE TABLE &#39;order_info&#39; ( &#39;id&#39; int(10) unsigned NOT NULL AUTO_INCREMENT COMMENT &#39;自增ID&#39;, &#39;order_id&#39; varchar(20) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;订单号&#39;, &#39;status&#39; tinyint(3) NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;订单状态&#39;, &#39;created_at&#39; timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;, &#39;updated_at&#39; timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT &#39;修改时间&#39;, PRIMARY KEY (&#39;id&#39;), UNIQUE KEY &#39;uk_order&#39; (&#39;order_id&#39;) ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT=&#39;订单表&#39;; `: {}} } model.go  package sqlboy import &#34;time&#34; type OrderInfo struct { Id uint32 `db:&#34;id&#34; json:&#34;id&#34;` //自增ID 	OrderId string `db:&#34;order_id&#34; json:&#34;order_id&#34;` //订单号 	Status int8 `db:&#34;status&#34; json:&#34;status&#34;` //订单状态 	CreatedAt time.Time `db:&#34;created_at&#34; json:&#34;created_at&#34;` //创建时间 	UpdatedAt time.Time `db:&#34;updated_at&#34; json:&#34;updated_at&#34;` //修改时间 } func (*OrderInfo) TableName() string { return `order_info` } dao.go  package sqlboy import ( &#34;context&#34; &#34;github.com/jmoiron/sqlx&#34; ) type contextTxKey struct{} type Dao struct { db *sqlx.DB } func NewDao(db *sqlx.DB) *Dao { return &amp;Dao{ db: db, } } func (d *Dao) InTx(ctx context.Context, fn func(ctx context.Context) error) error { tx, err := d.db.Begin() if err != nil { return err } defer func() { _ = tx.Rollback() }() err = fn(context.WithValue(ctx, contextTxKey{}, tx)) if err != nil { return err } return tx.Commit() } func (d *Dao) DB(ctx context.Context) DbTx { tx, ok := ctx.Value(contextTxKey{}).(*sqlx.Tx) if ok { return tx } return d.db } transaction.go  package sqlboy import ( &#34;context&#34; &#34;database/sql&#34; &#34;github.com/jmoiron/sqlx&#34; ) type Transaction interface { InTx(context.Context, func(ctx context.Context) error) error } func NewTransaction(d *Dao) Transaction { return d } type DbTx interface { QueryRowxContext(ctx context.Context, query string, args ...interface{}) *sqlx.Row QueryxContext(ctx context.Context, query string, args ...interface{}) (*sqlx.Rows, error) NamedExecContext(ctx context.Context, query string, arg interface{}) (sql.Result, error) ExecContext(ctx context.Context, query string, args ...interface{}) (sql.Result, error) } query_table.go (这个文件只展示一部分)  package sqlboy import &#34;context&#34; type OrderInfoDao interface { CreateOrderInfo(ctx context.Context, orderInfo *OrderInfo) error BatchCreateOrderInfo(ctx context.Context, list []*OrderInfo, batchSize int) error FindOrderInfo(ctx context.Context, id uint32) (*OrderInfo, error) UpdateOrderInfo(ctx context.Context, orderInfo *OrderInfo) error DeleteOrderInfo(ctx context.Context, id uint32) error FindByOrderId(ctx context.Context, orderId string) (*OrderInfo, error) UpdateByOrderId(ctx context.Context, orderInfo *OrderInfo) error DeleteByOrderId(ctx context.Context, orderId string) error } type OrderInfoImpl struct { dao *Dao } func NewOrderInfoDao(dao *Dao) OrderInfoDao { return &amp;OrderInfoImpl{ dao: dao, } } func (d *OrderInfoImpl) CreateOrderInfo(ctx context.Context, orderInfo *OrderInfo) error { _, err := d.dao.DB(ctx).NamedExecContext(ctx, &#34;INSERT INTO `order_info` (`id`,`order_id`,`status`,`created_at`,`updated_at`) VALUES (:id,:order_id,:status,:created_at,:updated_at)&#34;, orderInfo) return err } func (d *OrderInfoImpl) BatchCreateOrderInfo(ctx context.Context, list []*OrderInfo, batchSize int) error { return d.dao.InTx(ctx, func(ctx context.Context) error { for i := 0; i &lt; len(list); i += batchSize { ends := i + batchSize if ends &gt; len(list) { ends = len(list) } _, err := d.dao.DB(ctx).NamedExecContext(ctx, &#34;INSERT INTO `order_info` (`id`,`order_id`,`status`,`created_at`,`updated_at`) VALUES (:id,:order_id,:status,:created_at,:updated_at)&#34;, list[i:ends]) if err != nil { return err } } return nil }) } 设计  go AST
这个在前文有提到过，用来做输入的解析，建表语句的读取。这里我还把部分输出任务也给了他 （其实输出不应该用AST，效率低，且难以维护，这里只是为了尝试） ANTLR vs yacc
调研的时候发现很多ddl to struct的项目都是直接引用的一个使用yacc解析sql的库。 不过在经过对比之后，我发现yacc比较古老，而且还得自己去实现分词，因此直接放弃，采用更先进的ANTLR。 go template
输出是用的go原生text/template渲染，为了减少依赖，除了ANTLR，就没打算用第三方库。  整体架构 小结 这是sqlboy这个系列的第一篇文章，主要是写自己的想法由来，后续还将打算写四篇文章讲述具体实现细节。 这个项目已经完成了，欢迎大家使用并给我提bug。
项目源码 https://github.com/lemon-1997/sqlboy  
]]></content></entry><entry><title>如何在go中写好单元测试</title><url>/post/best-test.html</url><categories><category>最佳实践</category></categories><tags><tag>go</tag><tag>单元测试</tag></tags><content type="html"><![CDATA[当你还在用postman测试你的api时，那表明你还没找到使用go的最佳姿势，阅读这篇文章，一起来了解下go内置的测试框架，这会对你有所帮助。
单元测试 单元测试是我们项目开发中不可缺少的一部分，如果一个go项目没有单元测试，且刚好项目交接到你手里，由你来维护，那会很棘手，没有测试，意味着无法掌控这个项目，它就像一个定时炸弹，随时会产生bug。作为程序员，我们必须好好了解下单元测试。
单元测试基本概念  单元测试：应用中最小可测试部分，能够单独运行，用于被检测代码是否按照预期工作 测试用例：是一组测试，包括输入，执行条件，以及预期结果等 覆盖率：测试的度量，用来衡量代码被测试的比例 测试驱动开发：先有测试，后再通过修改代码使测试通过的开发方式  单元测试的优点  易于调试 提前发现问题 短代码，简洁且高质量  可能有人会觉得写单元测试是一件很麻烦的事，认为浪费时间。但也许你写了单元测试，他能减少你项目出问题排错的时间，也能让你更好的运行指定的代码，更精准的找到问题。写单元测试其实为你带来了效率上的提升，并且在go中，为项目增加单元测试非常简单。
go内置测试框架 go官方包自带了测试框架，这不仅仅是go官方为了所有gopher能更方便的写测试，也直接证明了测试的重要性，官方直接把他丢进了std里，可见一斑。 在最新版本的go中，go团队加入了模糊测试，不过本篇文章只涉及单元测试，不会讲解基准测试以及模糊测试。
testing.T 在go中写单元测试，我们先写了解下 testing.T 这个类型以及其持有的方法
// TB is the interface common to T and B. type TB interface { Cleanup(func()) Error(args ...interface{}) Errorf(format string, args ...interface{}) Fail() FailNow() Failed() bool Fatal(args ...interface{}) Fatalf(format string, args ...interface{}) Helper() Log(args ...interface{}) Logf(format string, args ...interface{}) Name() string Skip(args ...interface{}) SkipNow() Skipf(format string, args ...interface{}) Skipped() bool TempDir() string // A private method to prevent users implementing the  // interface and so future additions to it will not  // violate Go 1 compatibility.  private() } type T struct { common isParallel bool context *testContext // For running tests and subtests. } var _ TB = (*T)(nil) 这里顺便给大家科普下，var _ TB = (*T)(nil) 这行语句，使用了编译时断言，如果 T 没有实现 TB 里定义的方法，那么编译就会报错，这样能让开发者及时发现问题，避免错误的发生。大家平常写代码也可以使用编译时断言来让自己的项目更加健壮。
常用方法
 Logf：记录日志，提供代码测试时运行信息 Errorf：记录日志，但会让测试不能通过 Fatalf：记录日志，测试立即停止且测试失败 Skipf：记录日志，并跳过该测试函数 Cleanup：清理函数，资源的释放 Helper：辅助函数，打印文件行信息  官方例子 testing.T 看起来比较简单，老规矩，先上官方例子
package greetings import ( &#34;testing&#34; &#34;regexp&#34; ) // TestHelloName calls greetings.Hello with a name, checking // for a valid return value. func TestHelloName(t *testing.T) { name := &#34;Gladys&#34; want := regexp.MustCompile(`\b`+name+`\b`) msg, err := Hello(&#34;Gladys&#34;) if !want.MatchString(msg) || err != nil { t.Fatalf(`Hello(&#34;Gladys&#34;) = %q, %v, want match for %#q, nil`, msg, err, want) } } // TestHelloEmpty calls greetings.Hello with an empty string, // checking for an error. func TestHelloEmpty(t *testing.T) { msg, err := Hello(&#34;&#34;) if msg != &#34;&#34; || err == nil { t.Fatalf(`Hello(&#34;&#34;) = %q, %v, want &#34;&#34;, error`, msg, err) } } 上面的例子大家应该都看得懂，我就不总结具体的测试流程了，这里主要是为了给大家展示在go中写单元测试是多么方便。
最佳实践 starting 在开始之前，我们要先了解go的测试规范
 文件名：前缀为测试代码的文件名，以 _test.go 结尾（go build 会忽略这些文件） 文件位置：位于测试的代码同一 package 下 函数名：Test 为前缀，后面是测试函数名，函数参数为 *testing.T  table test table test 是一种很棒的写法，它能让你的测试代码足够清晰，让你的测试用例易于维护，该写法可以在各种库中见到。其大体流程为：
 定义tests 为测试用例，其结构为匿名结构体切片 []struct{} 补充匿名结构体变量，定义好输入输出，丰富测试用例 遍历测试用例，调用测试方法，判断测试结果是否符合预期 使用 testing.T 里的方法记录日志或让测试失败  go源码 encoding/json/encode_test.go 里就采用了这种测试方式
func TestRoundtripStringTag(t *testing.T) { tests := []struct { name string in StringTag want string // empty to just test that we roundtrip 	}{ { name: &#34;AllTypes&#34;, in: StringTag{ BoolStr: true, IntStr: 42, UintptrStr: 44, StrStr: &#34;xzbit&#34;, NumberStr: &#34;46&#34;, }, want: `{ &#34;BoolStr&#34;: &#34;true&#34;, &#34;IntStr&#34;: &#34;42&#34;, &#34;UintptrStr&#34;: &#34;44&#34;, &#34;StrStr&#34;: &#34;\&#34;xzbit\&#34;&#34;, &#34;NumberStr&#34;: &#34;46&#34; }`, }, { // See golang.org/issues/38173. 	name: &#34;StringDoubleEscapes&#34;, in: StringTag{ StrStr: &#34;\b\f\n\r\t\&#34;\\&#34;, NumberStr: &#34;0&#34;, // just to satisfy the roundtrip 	}, want: `{ &#34;BoolStr&#34;: &#34;false&#34;, &#34;IntStr&#34;: &#34;0&#34;, &#34;UintptrStr&#34;: &#34;0&#34;, &#34;StrStr&#34;: &#34;\&#34;\\u0008\\u000c\\n\\r\\t\\\&#34;\\\\\&#34;&#34;, &#34;NumberStr&#34;: &#34;0&#34; }`, }, } for _, test := range tests { t.Run(test.name, func(t *testing.T) { // Indent with a tab prefix to make the multi-line string 	// literals in the table nicer to read. 	got, err := MarshalIndent(&amp;test.in, &#34;\t\t\t&#34;, &#34;\t&#34;) if err != nil { t.Fatal(err) } if got := string(got); got != test.want { t.Fatalf(&#34; got: %s\nwant: %s\n&#34;, got, test.want) } // Verify that it round-trips. 	var s2 StringTag if err := Unmarshal(got, &amp;s2); err != nil { t.Fatalf(&#34;Decode: %v&#34;, err) } if !reflect.DeepEqual(test.in, s2) { t.Fatalf(&#34;decode didn&#39;t match.\nsource: %#v\nEncoded as:\n%s\ndecode: %#v&#34;, test.in, string(got), s2) } }) } } mock test 当我们由于某些原因，不好直接调用我们的函数去做测试时，我们应该如何做呢？答案就是 interface ，如果我们的测试函数输入刚好是 interface 时，那很棒，如果不是呢，考虑下将函数参数抽象为 interfae ，是否你的代码会更好。
直接看下面的例子，这也是来自go源码 io/io_test.go
type zeroErrReader struct { err error } func (r zeroErrReader) Read(p []byte) (int, error) { return copy(p, []byte{0}), r.err } type errWriter struct { err error } func (w errWriter) Write([]byte) (int, error) { return 0, w.err } // In case a Read results in an error with non-zero bytes read, and // the subsequent Write also results in an error, the error from Write // is returned, as it is the one that prevented progressing further. func TestCopyReadErrWriteErr(t *testing.T) { er, ew := errors.New(&#34;readError&#34;), errors.New(&#34;writeError&#34;) r, w := zeroErrReader{err: er}, errWriter{err: ew} n, err := Copy(w, r) if n != 0 || err != ew { t.Errorf(&#34;Copy(zeroErrReader, errWriter) = %d, %v; want 0, writeError&#34;, n, err) } } 这里通过 zeroErrReader 和 errWriter mock数据，分别实现了 io.Reader 以及 io.Writer ，当我们写测试时，具体怎样mock取决于你想测试的东西。
dependency injection 有些时候，我们的测试需要外部依赖，例如我们需要数据库实例或者http server，这时候我们可以利用 TestMain 的特性
来看看go源码 net/http/main_test.go
func TestMain(m *testing.M) { setupTestData() installTestHooks() st := m.Run() testHookUninstaller.Do(uninstallTestHooks) if testing.Verbose() { printRunningGoroutines() printInflightSockets() printSocketStats() } forceCloseSockets() os.Exit(st) } 执行测试的时候，会优先执行 TestMain ，然后再通过 m.Run() 执行其他的测试，最好释放我们的资源，这样就解决了我们的资源依赖问题。这里给出一个模板参考，具体的 setup() 和 teardown() 的实现由自己的项目代码所决定。
func setup() { fmt.Printf(&#34;Setup&#34;) } func teardown() { fmt.Printf(&#34;Teardown&#34;) } func TestMain(m *testing.M) { setup() code := m.Run() teardown() os.Exit(code) } 结语 这篇文章所讲的东西都是自己最近写单元测试的一些感悟，如果有错误可在下方评论指出，如果对你有帮助，我也很希望在评论区看到你的评论。 好了，到这里就结束了，感谢阅读！
]]></content></entry><entry><title>mysql事务在go语言中的正确打开方式</title><url>/post/best-transaction.html</url><categories><category>最佳实践</category></categories><tags><tag>go</tag><tag>mysql</tag></tags><content type="html"><![CDATA[相信大家在做curd项目时经常会使用到mysql中的事务，这篇文章将会展示在go中实现mysql事务的几种方式，希望阅读后能够给你带来启发。
mysql事务 mysql的事务保证了我们应用程序和业务逻辑的可靠，是我们日常开发重要的一环，我们必须了解其特性，才能更好的使用它。
ACID模型 首先介绍下 ACID 模型
 A：原子性。事务中的操作要么 commit 成功，要么全部 rollback C：一致性。事务的执行前后数据要一致，主要是保护数据丢失，比如 innodb 中的崩溃恢复机制 I：隔离性。事务内部的操作与其他事务的隔离，比如隔离级别以及锁机制 D：持久性。事务提交后对数据库具有永久性  使用场景 上面的ACID其实已经可以体现出事务的使用场景。举几个例子
 用户下单时，需要在订单表创建一条记录，并扣减商品的库存 转账时，一方扣款，另一方必须增加对应的金额 查询到其他事务还没有提交的数据，导致脏读  了解了什么是事务，接下来我们一起看下在go中是怎么开启事务。
go实现方式 go开启事务的几个步骤
 开启事务 执行数据库操作 结束事务  提交事务 回滚事务    看起来很简单，就三个步骤而已，下面看下具体的代码实例。
go官方例子 先欣赏下go官方提供的例子
// CreateOrder creates an order for an album and returns the new order ID. func CreateOrder(ctx context.Context, albumID, quantity, custID int) (orderID int64, err error) { // Create a helper function for preparing failure results.  fail := func(err error) (int64, error) { return fmt.Errorf(&#34;CreateOrder: %v&#34;, err) } // Get a Tx for making transaction requests.  tx, err := db.BeginTx(ctx, nil) if err != nil { return fail(err) } // Defer a rollback in case anything fails.  defer tx.Rollback() // Confirm that album inventory is enough for the order.  var enough bool if err = tx.QueryRowContext(ctx, &#34;SELECT (quantity &gt;= ?) from album where id = ?&#34;, quantity, albumID).Scan(&amp;enough); err != nil { if err == sql.ErrNoRows { return fail(fmt.Errorf(&#34;no such album&#34;)) } return fail(err) } if !enough { return fail(fmt.Errorf(&#34;not enough inventory&#34;)) } // Update the album inventory to remove the quantity in the order.  _, err = tx.ExecContext(ctx, &#34;UPDATE album SET quantity = quantity - ? WHERE id = ?&#34;, quantity, albumID) if err != nil { return fail(err) } // Create a new row in the album_order table.  result, err := tx.ExecContext(ctx, &#34;INSERT INTO album_order (album_id, cust_id, quantity, date) VALUES (?, ?, ?, ?)&#34;, albumID, custID, quantity, time.Now()) if err != nil { return fail(err) } // Get the ID of the order item just created.  orderID, err := result.LastInsertId() if err != nil { return fail(err) } // Commit the transaction.  if err = tx.Commit(); err != nil { return fail(err) } // Return the order ID.  return orderID, nil } 这是go官方提供的例子，大体的代码流程如下
 通过 DB.Begin / DB.BeginTx 获取 sql.Tx 延迟调用 Tx.Rollback 执行数据库的插入修改语句 没有出错，通过 Tx.Commit 提交  这种方式看起来很不错，失败了能回滚，成功则一起提交，很清晰的表明事务的整个流程。 但是当你项目的业务逻辑愈加复杂，或者事务里面的某个表新加了字段，需要去调整SQL语句的时候，你必须在这个大函数里面去修改，这看起来很危险。 像这个例子所体现的，该函数里面做了多个SQL操作，除了单一的业务场景，很难被别的地方复用。
mysql事务封装 于是，针对上面的问题，可以先将事务的操作封装起来，并抽离出数据库执行SQL的函数 fn
func WithTransaction(db *sql.DB, fn func(sql.Tx) error) (err error) { tx, err := db.Begin() if err != nil { return } defer func() { if p := recover(); p != nil { // a panic occurred, rollback and repanic 	tx.Rollback() panic(p) } else if err != nil { // something went wrong, rollback 	tx.Rollback() } else { // all good, commit 	err = tx.Commit() } }() err = fn(tx) return err } 因此使用起来只需要编写相应的数据库操作函数 fn，我们可以对订单，商品数据的操作做更细粒度的封装，就像下面这样
err = WithTransaction(db, func(tx sql.Tx) error { // insert a record into order table 	res, err := dao.CreateOrder(tx,order) if err != nil { return err } // update product inventory 	res, err = dao.UpdateInventory(tx,product) if err != nil { return err } }) 好了，目前看来这个例子已经很完美了，我们不需要写过多的重复代码，事务的操作，数据库执行的SQL都能被很好的复用。 但是还有个问题，上面的 CreateOrder 和 UpdateInventory 函数需要传入 sql.Tx，这会使调用者难以下手，理论上调用者不应该关心传入哪个数据库，他只想完成创建订单，扣减库存的操作。 而且，当你的事务只需要执行一次SQL时，并不需要开启事务的，但你的传参确实 sql.Tx，这会导致多余的代码，且很不优雅。
interface登场 假设我们现在有一个数据库操作对象 Dao
type Dao struct{ db *sql.Db } func (d *Dao ) CreateOrder(ctx context, order entity.Order) error { d.db.ExecContext(ctx, `Insert into`, order) } func (d *Dao ) UpdateInventory(ctx context, product entity.Product) error { d.db.ExecContext(ctx, `Insert into`, product) } 如果我们现在需要开启一个事务，这个事务里需要执行 CreateOrder 和 UpdateInventory，这个时候，很多人的第一个想法是重新写一个函数，因为现有的函数都是由 sql.Db 去执行，而不是 sql.Tx。 那我们有没有办法减少重复代码的开发呢？答案是有的，那就是 interface{}
// Queries is a common interface that is used by both *sqlx.DB and *sqlx.Tx. type Queries interface { QueryRowxContext(ctx context.Context, query string, args ...interface{}) *sqlx.Row QueryxContext(ctx context.Context, query string, args ...interface{}) (*sqlx.Rows, error) NamedExecContext(ctx context.Context, query string, arg interface{}) (sql.Result, error) ExecContext(ctx context.Context, query string, args ...interface{}) (sql.Result, error) } 在这里，我们定义了一个叫 Queries 的 interface 去实现 sql.Db 和 sql.Tx 。那么再对 Dao 重新调整一下，并对外提供一个 New 函数，支持传入 sql.Db 和 sql.Tx
type Dao struct{ db Queries } fun NewOderDao (db Queries) *Dao{ return &amp;oderDao{db:db} } 这样一来，我们通过 Queries 使 Dao 中的函数可以同时是普通执行或者开启事务执行，且调用相关函数时不需要传入数据库对象。那么问题来了，如何与上面封装好的 WithTransaction一起使用呢？
best practices 上面的 WithTransaction 函数注入了 sql.Tx，那么，我们可以将两者结合，改变一下注入对象，将 Dao 注入给 fn
func WithTransaction(db *sql.DB, fn func(dao *Dao) error) (err error) { tx, err := db.Beginx() if err != nil { return } defer func() { if p := recover(); p != nil { // a panic occurred, rollback and repanic 	tx.Rollback() panic(p) } else if err != nil { // something went wrong, rollback 	tx.Rollback() } else { // all good, commit 	err = tx.Commit() } }() // inject 	dao := NewOderDao(tx) err = fn(dao) return err } 这样一来，调用 WithTransaction 就可以拿到数据库操作对象了。最后别忘了补充单元测试，那是你go项目中可靠性以及可维护性的一部分
// init db dao func init(){ } func Test_WithTransaction(t *testing.T) { tests := []struct{ fn func(dao *Dao)error // out? or else  }{ { func(dao *Dao)error{ ctx, cancel := context.WithCancel(context.Background()) cancel() err := dao.CreateOrderInfo(ctx, &amp;order) if err != nil { t.Logf(&#34;error %v emit roollback&#34;, err) return err } t.Logf(&#34;comit order %v&#34;, order) return nil }, }, { func(dao *Dao)error{ return nil }, }, } for _, tt := range tests{ _ = WithTransaction(db, tt.fn) } } 结语 关于mysql的事务操作，相信还有更优秀的写法，这篇文章的例子也许不是最好的，但希望能给你带来启发，有兴趣的可以在下方评论与我交流。
]]></content></entry><entry><title>后端开发必备的工具及网站</title><url>/post/other-develop.html</url><categories><category>随想记录</category></categories><tags><tag>后端</tag></tags><content type="html">other-develop</content></entry><entry><title>lemon</title><url>/about/</url><categories/><tags><tag>lemon</tag></tags><content type="html">大家好，我是lemon，目前在深圳从事互联网相关的工作。从事后端开发已经有几年时间了，主要使用的语言是go，平常喜欢去研究go，一直致力于写出更优雅的go代码。建立此博客的初衷一是为了分享给其他人，二是自己分享了，也会去总结，自己能够有所收获。
博客专题 最佳实践 源码分析 项目实战 框架教程 随想记录 博客地址 国内： https://lemon-1997.pages.dev/ 国外： https://lemon-1997.github.io/ 联系方式 Github： https://github.com/lemon-1997 邮箱：lemom_ 1997@126.com 评论：参与下方评论与我交流</content></entry></search>